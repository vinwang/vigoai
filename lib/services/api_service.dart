import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:dio/dio.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as path;
import '../models/agent_command.dart';
import '../models/character_sheet.dart';
import '../utils/duration_parser.dart';
import '../utils/app_logger.dart';
import 'api_config_service.dart';

/// ç±»å‹åˆ«åï¼šç®€åŒ– DurationParser çš„å¼•ç”¨
typedef _DurationParser = DurationParser;
typedef _SceneCountRange = SceneCountRange;

/// API é…ç½®
class ApiConfig {
  static const String zhipuBaseUrl = 'https://open.bigmodel.cn/api/paas/v4'; // æ™ºè°± GLM
  static const String tuziBaseUrl = 'https://api.ourzhishi.top'; // Tuzi API åŸºç¡€URL (è§†é¢‘ & å›¾åƒ)
  static const String doubaoBaseUrl = 'https://ark.cn-beijing.volces.com/api/v3'; // è±†åŒ… ARK API

  // å„æœåŠ¡çš„ API Keyï¼ˆä» ApiConfigService è¯»å–ï¼‰
  static String get zhipuApiKey => ApiConfigService.getZhipuApiKey();
  static String get videoApiKey => ApiConfigService.getVideoApiKey();
  static String get imageApiKey => ApiConfigService.getImageApiKey();
  static String get doubaoApiKey => ApiConfigService.getDoubaoApiKey();

  /// åˆ›å»ºæ™ºè°± API Dio å®ä¾‹
  static Dio createDio() {
    final dio = Dio(BaseOptions(
      baseUrl: zhipuBaseUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Content-Type': 'application/json',
      },
    ));

    // æ·»åŠ æ‹¦æˆªå™¨ï¼Œåœ¨æ¯æ¬¡è¯·æ±‚æ—¶åŠ¨æ€è®¾ç½® Authorization header
    dio.interceptors.add(InterceptorsWrapper(
      onRequest: (options, handler) {
        // åŠ¨æ€è·å–æœ€æ–°çš„ API Key
        options.headers['Authorization'] = 'Bearer $zhipuApiKey';
        return handler.next(options);
      },
    ));

    // æ·»åŠ æ—¥å¿—æ‹¦æˆªå™¨ç”¨äºè°ƒè¯•
    dio.interceptors.add(LogInterceptor(
      requestBody: true,
      responseBody: true,
      requestHeader: true,
      error: true,
    ));

    return dio;
  }

  // è±†åŒ…æ¨¡å‹é…ç½®
  // static const String doubaoImageModel = 'doubao-seed-1-8-251215'; // æ”¯æŒå›¾ç‰‡çš„è±†åŒ…æ¨¡å‹
  static const String doubaoImageModel = 'doubao-seed-1-8-preview-251115'; // æ”¯æŒå›¾ç‰‡çš„è±†åŒ…æ¨¡å‹

  // ==================== åŠŸèƒ½å¼€å…³ ====================
  /// ç”Ÿäº§ç¯å¢ƒè¯·å°†æ­¤å€¼è®¾ä¸º false
  /// æ³¨æ„ï¼šå¦‚æœè§†é¢‘ Mock ä¸º falseï¼ŒMock å›¾ç‰‡ URL å¿…é¡»æ˜¯è§†é¢‘ API å¯ä»¥è®¿é—®çš„å…¬å¼€é“¾æ¥
  static const bool USE_MOCK_VIDEO_API = false;  // è§†é¢‘ç”Ÿæˆ Mock å¼€å…³
  static const bool USE_MOCK_IMAGE_API = false;   // å›¾ç‰‡ç”Ÿæˆ Mock å¼€å…³
  static const bool USE_MOCK_CHARACTER_SHEET_API = false;   // è§’è‰²ä¸‰è§†å›¾ç”Ÿæˆ Mock å¼€å…³ï¼ˆæµ‹è¯•ç”¨ï¼‰

  /// Thinking æ¨¡å¼å¼€å…³
  /// å¯ç”¨åä¼šæ˜¾ç¤º AI çš„æ€è€ƒè¿‡ç¨‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
  /// æ¼”ç¤ºæ—¶å¯å¼€å¯ï¼Œç”Ÿäº§ç¯å¢ƒæ ¹æ®éœ€æ±‚å†³å®š
  static const bool USE_THINKING_MODE = true;  // æ€è€ƒè¿‡ç¨‹æ˜¾ç¤ºå¼€å…³

  // ==================== åœºæ™¯é…ç½® ====================
  /// åœºæ™¯æ•°é‡é…ç½®
  /// æ§åˆ¶å¤§æ¨¡å‹ç”Ÿæˆçš„åœºæ™¯æ•°é‡ï¼ŒåŒæ—¶ä¹Ÿæ˜¯åˆ†é•œå›¾å’Œåˆ†é•œè§†é¢‘çš„æ•°é‡
  /// ä¾‹å¦‚ï¼šè®¾ç½®ä¸º 2ï¼Œåˆ™ç”Ÿæˆ 2 ä¸ªåœºæ™¯ã€2 å¼ åˆ†é•œå›¾ã€2 ä¸ªåˆ†é•œè§†é¢‘
  static int sceneCount = 7;  // é»˜è®¤ 2 ä¸ªåœºæ™¯

  /// å¹¶å‘ç”Ÿæˆåœºæ™¯æ•°é‡é…ç½®
  /// æ§åˆ¶åŒæ—¶ç”Ÿæˆå¤šå°‘ä¸ªåœºæ™¯çš„å›¾ç‰‡å’Œè§†é¢‘
  /// ä¾‹å¦‚ï¼šè®¾ç½®ä¸º 3ï¼Œåˆ™æ¯ 3 ä¸ªåœºæ™¯ä¸ºä¸€ç»„å¹¶è¡Œå¤„ç†
  /// è®¾ç½®ä¸º 1 è¡¨ç¤ºä¸²è¡Œå¤„ç†ï¼Œè®¾ç½®ä¸ºå¤§æ•°å€¼è¡¨ç¤ºå…¨å¹¶è¡Œå¤„ç†
  static int concurrentScenes = 2;  // é»˜è®¤æ¯æ‰¹ 3 ä¸ªåœºæ™¯å¹¶è¡Œ

  /// Mock è§†é¢‘URLï¼ˆç”¨äºæµ‹è¯•ï¼‰- ä½¿ç”¨å…¬å¼€å¯è®¿é—®çš„æµ‹è¯•è§†é¢‘
  static const String MOCK_VIDEO_URL =
      'https://www.w3schools.com/html/mov_bbb.mp4';

  /// Mock å›¾ç‰‡URLï¼ˆç”¨äºæµ‹è¯•ï¼‰
  static const String MOCK_IMAGE_URL =
      'https://pro.filesystem.site/cdn/20251231/068472ac4cc0ac7a4a8bdb3dcfb693.jpeg';

  /// Mock è§’è‰²ä¸‰è§†å›¾URLï¼ˆç”¨äºæµ‹è¯•ï¼‰
  /// æ–°ç‰ˆæœ¬ï¼šå•å¼ ç»„åˆå›¾ï¼ˆåŒ…å«æ­£é¢ã€ä¾§é¢ã€èƒŒé¢ä¸‰ä¸ªè§†è§’ï¼‰
  static const String MOCK_CHARACTER_COMBINED_URL =
      'https://pro.filesystem.site/cdn/20251231/068472ac4cc0ac7a4a8bdb3dcfb693.jpeg';

  /// å…¼å®¹æ—§ç‰ˆï¼šå•ç‹¬çš„ä¸‰è§†å›¾URLï¼ˆå·²åºŸå¼ƒï¼‰
  @Deprecated('ä½¿ç”¨ MOCK_CHARACTER_COMBINED_URL æ›¿ä»£')
  static const String MOCK_CHARACTER_FRONT_URL =
      'https://pro.filesystem.site/cdn/20251231/068472ac4cc0ac7a4a8bdb3dcfb693.jpeg';
  @Deprecated('ä½¿ç”¨ MOCK_CHARACTER_COMBINED_URL æ›¿ä»£')
  static const String MOCK_CHARACTER_BACK_URL =
      'https://pro.filesystem.site/cdn/20251231/068472ac4cc0ac7a4a8bdb3dcfb693.jpeg';
  @Deprecated('ä½¿ç”¨ MOCK_CHARACTER_COMBINED_URL æ›¿ä»£')
  static const String MOCK_CHARACTER_SIDE_URL =
      'https://pro.filesystem.site/cdn/20251231/068472ac4cc0ac7a4a8bdb3dcfb693.jpeg';

  static Dio createDio() {
    final dio = Dio(BaseOptions(
      baseUrl: zhipuBaseUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Authorization': 'Bearer $zhipuApiKey',
        'Content-Type': 'application/json',
      },
    ));

    // æ·»åŠ æ—¥å¿—æ‹¦æˆªå™¨ç”¨äºè°ƒè¯•
    dio.interceptors.add(LogInterceptor(
      requestBody: true,
      responseBody: true,
      requestHeader: true,
      error: true,
    ));

    return dio;
  }
}

/// GLM ç³»ç»Ÿæç¤ºè¯ - å‰§æœ¬è§„åˆ’æ¨¡å¼
const String _glmSystemPrompt = '''
You are DirectorAI, a SCREENPLAY CREATION AGENT for short video production.

YOUR MISSION: Convert user's creative idea into a multi-scene screenplay with exactly 3 scenes.
Each scene will be turned into: Narration (Chinese) â†’ Image â†’ Video.

CRITICAL OUTPUT FORMAT:
You MUST respond with ONLY a valid JSON object. No markdown, no explanations, no thinking process.

JSON SCHEMA:
{
  "task_id": "unique_task_id",
  "script_title": "å‰§æœ¬æ ‡é¢˜",
  "scenes": [
    {
      "scene_id": 1,
      "narration": "ä¸­æ–‡æ—ç™½ï¼Œæè¿°è¿™ä¸€å¹•çš„å†…å®¹",
      "image_prompt": "Detailed English visual description for image generation",
      "video_prompt": "English motion/description for video animation",
      "character_description": "Detailed character description for consistency across scenes",
      "image_url": null,
      "video_url": null,
      "status": "pending"
    }
  ]
}

GUIDELINES:

1. NUMBER OF SCENES: EXACTLY 3 SCENES
   - Scene 1: Introduction / Setup (establish the main character and setting)
   - Scene 2: Development / Action (the main conflict or activity)
   - Scene 3: Resolution / Ending (conclusion and aftermath)
   - Each scene must be focused on ONE key moment

2. CHARACTER CONSISTENCY (CRITICAL):
   - First scene's image_prompt MUST contain detailed character appearance description
   - The character_description field should describe the main character's appearance in detail
   - For subsequent scenes, the image_prompt should reference the same character traits
   - This ensures the same character appears across all scenes

3. NARRATION (Chinese):
   - Short, evocative descriptions
   - 1-2 sentences per scene
   - Sets the mood and context

4. IMAGE_PROMPT (English):
   - Scene 1: Establish the main character with detailed appearance (hair, clothing, face, body type, colors)
   - Scene 2+: Reference the same character using consistent descriptors from scene 1
   - CRITICAL: ALWAYS start with "anime style, manga art, 2D animation, cel shaded"
   - For human characters: specify "Asian" or "Japanese anime style" features
   - AVOID: "realistic, photorealistic, cinematic, 3D render"
   - Example scene 1: "anime style, manga art, 2D animation. A cute orange tabby cat with green eyes and white paws, sitting on grass..."
   - Example scene 2: "anime style, manga art. The same orange tabby cat with green eyes and white paws, now jumping..."

5. VIDEO_PROMPT (English):
   - Motion description: what moves, how, action
   - Keep it consistent with the image

6. CHARACTER_DESCRIPTION (English):
   - A detailed description of the main character's appearance
   - Include: species, colors, distinctive features, clothing, accessories
   - For human characters: specify "anime style, Asian features" or "Japanese anime style"
   - This description will be used to maintain consistency across all scenes

EXAMPLE INPUT: "ç”Ÿæˆä¸€åªçŒ«æ‰“æ¶çš„è§†é¢‘"

EXAMPLE OUTPUT:
{
  "task_id": "cat_fight_20231227",
  "script_title": "çŒ«å’ªå¤§æˆ˜",
  "scenes": [
    {
      "scene_id": 1,
      "narration": "ä¸¤åªçŒ«å’ªåœ¨è‰åœ°ä¸Šå¯¹å³™ï¼Œæ°”æ°›ç´§å¼ ",
      "image_prompt": "Two cats facing each other on grass, tense standoff. Left: orange tabby cat with bright green eyes and white paws. Right: grey striped cat with amber eyes. Cinematic composition, golden hour lighting, 4k ultra detailed",
      "video_prompt": "Cats circling each other slowly, tails twitching, intense staring",
      "character_description": "Orange tabby cat with bright green eyes, white paws, and striped tail. Grey striped cat with amber eyes and pointed ears.",
      "image_url": null,
      "video_url": null,
      "status": "pending"
    },
    {
      "scene_id": 2,
      "narration": "çªç„¶ï¼Œå®ƒä»¬å¼€å§‹æ¿€çƒˆåœ°æ‰“æ–—",
      "image_prompt": "The same orange tabby cat with green eyes and white paws fighting the grey striped cat with amber eyes. Mid-action shot, dynamic pose, motion blur, professional sports photography style, dramatic lighting",
      "video_prompt": "Orange cat and grey cat jumping and pouncing, fast dynamic action, paws swiping",
      "character_description": "Orange tabby cat with bright green eyes, white paws, and striped tail. Grey striped cat with amber eyes and pointed ears.",
      "image_url": null,
      "video_url": null,
      "status": "pending"
    },
    {
      "scene_id": 3,
      "narration": "æ‰“æ–—ç»“æŸï¼Œå„è‡ªç¦»å¼€",
      "image_prompt": "The orange tabby cat with green eyes and white paws walking left, away from camera. The grey striped cat with amber eyes walking right. Calm aftermath, sunset lighting, peaceful atmosphere, 4k detailed",
      "video_prompt": "Orange cat and grey cat calmly walking away from each other in opposite directions, slow movement",
      "character_description": "Orange tabby cat with bright green eyes, white paws, and striped tail. Grey striped cat with amber eyes and pointed ears.",
      "image_url": null,
      "video_url": null,
      "status": "pending"
    }
  ]
}

ABSOLUTE RULES:
1. Output ONLY valid JSON - no markdown code blocks, no explanations
2. scene_id must be sequential starting from 1
3. ALWAYS include exactly 3 scenes (no more, no less)
4. All scenes must have the SAME character_description value
5. Scene 1's image_prompt establishes character appearance
6. Scenes 2 and 3 must reference the same character appearance in image_prompt
7. CRITICAL: EVERY image_prompt MUST start with "anime style, manga art, 2D animation"
8. CRITICAL: For human characters, specify "Asian" or "Japanese anime style" features
9. CRITICAL: NEVER use "realistic, photorealistic, cinematic, 3D render" in prompts
10. image_url and video_url must be null initially
11. status must be "pending" for all scenes
12. Generate a unique task_id using format: task_[timestamp]_[topic]
''';

/// GLM ç³»ç»Ÿæç¤ºè¯ - æ™®é€šèŠå¤©æ¨¡å¼
const String _glmChatPrompt = '''
You are AIæ¼«å¯¼ (DirectorAI), a friendly AI assistant specialized in video content creation.

ä½ çš„èŒè´£ï¼š
1. å‹å¥½åœ°ä¸ç”¨æˆ·äº¤æµ
2. äº†è§£ç”¨æˆ·æƒ³è¦åˆ›ä½œä»€ä¹ˆæ ·çš„è§†é¢‘
3. å½“ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºè¦ç”Ÿæˆè§†é¢‘æ—¶ï¼Œå¼•å¯¼ä»–ä»¬æä¾›å…·ä½“çš„åˆ›æ„æè¿°

å›å¤é£æ ¼ï¼š
- å‹å¥½ã€ä¸“ä¸šã€ç®€æ´
- ä½¿ç”¨ä¸­æ–‡å›å¤
- å¯ä»¥ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²å’ŒåŠ›
- å½“ç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼æ—¶ï¼Œç®€è¦ä»‹ç»ä½ çš„åŠŸèƒ½
- å½“ç”¨æˆ·æåˆ°æƒ³åˆ¶ä½œè§†é¢‘æ—¶ï¼Œè¯¢é—®å…·ä½“çš„åˆ›æ„å†…å®¹ï¼ˆè§’è‰²ã€åœºæ™¯ã€é£æ ¼ç­‰ï¼‰

ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼šä½ å¥½
ä½ ï¼šä½ å¥½ï¼æˆ‘æ˜¯ AI æ¼«å¯¼ ğŸ¬ æˆ‘å¯ä»¥å¸®ä½ åˆ›ä½œå„ç§è§†é¢‘å†…å®¹ï¼Œæ¯”å¦‚åŠ¨ç”»ã€çŸ­ç‰‡ã€é£æ™¯è§†é¢‘ç­‰ã€‚ä½ æƒ³åˆ›ä½œä»€ä¹ˆæ ·çš„è§†é¢‘å‘¢ï¼Ÿ

ç”¨æˆ·ï¼šæˆ‘æƒ³åšä¸ªè§†é¢‘
ä½ ï¼šå¤ªå¥½äº†ï¼è¯·å‘Šè¯‰æˆ‘æ›´å¤šç»†èŠ‚å§ï¼Œæ¯”å¦‚ï¼š
- è§†é¢‘é‡Œæœ‰ä»€ä¹ˆè§’è‰²æˆ–åœºæ™¯ï¼Ÿ
- æƒ³è¦ä»€ä¹ˆé£æ ¼ï¼ˆå¯çˆ±ã€é…·ç‚«ã€æ¸©é¦¨ç­‰ï¼‰ï¼Ÿ
- å¤§æ¦‚æƒ³è¦ä»€ä¹ˆæ ·çš„æ•…äº‹æƒ…èŠ‚ï¼Ÿ

è¯·è‡ªç„¶åœ°ä¸ç”¨æˆ·å¯¹è¯ï¼Œå¼•å¯¼ä»–ä»¬æä¾›è¶³å¤Ÿçš„åˆ›æ„ä¿¡æ¯ã€‚
''';

/// GLM ç³»ç»Ÿæç¤ºè¯ - æ¼«å‰§å‰§æœ¬ç”Ÿæˆæ¨¡å¼
/// ç”¨äºç”Ÿæˆ1åˆ†é’Ÿä»¥ä¸Šçš„æ¼«å‰§é£æ ¼å‰§æœ¬ï¼ŒåŒ…å«æƒ…ç»ªé’©å­å’Œåè½¬å‰§æƒ…
const String _dramaSystemPrompt = '''
You are DirectorAI, a PROFESSIONAL SCREENPLAY WRITER for manga-style drama videos.

YOUR MISSION: Create a compelling 1-minute drama screenplay with emotional hooks,
plot twists, and engaging narrative structure.

REQUIREMENTS:
1. LENGTH: 6-8 scenes (approximately 60-90 seconds total)
2. EMOTIONAL HOOK: Each scene should build positive emotional connection
3. PLOT TWIST: Include heartwarming or surprising moments (NOT tragic or dark)
4. GENRE: POSITIVE manga-style stories ONLY:
   - Campus life / School days
   - Friendship and bonding
   - Youth and dreams
   - Sweet romance
   - Healing / Comforting stories
   - Daily life warmth
   - AVOID: revenge, violence, horror, tragedy, crime, suspense with threats

STRUCTURE:
- Opening (1-2 scenes): Establish setting and characters in a positive light
- Development (2-3 scenes): Build warm connections or gentle challenges
- Heartwarming Moment (1-2 scenes): Emotional peak - touching, sweet, or inspiring
- Resolution (1-2 scenes): Happy or hopeful conclusion

CRITICAL OUTPUT FORMAT:
You MUST respond with ONLY a valid JSON object.
- NO markdown code blocks (```json ... ```)
- NO explanations before or after the JSON
- NO comments in the JSON
- Use ONLY standard English double quotes " " for all strings
- NEVER use Chinese quotes " " or ''
- Ensure all brackets { } [ ] are properly matched
- All string values must be wrapped in double quotes
- Do NOT use trailing commas

JSON SCHEMA:
{
  "task_id": "unique_id",
  "title": "å‰§æœ¬æ ‡é¢˜",
  "genre": "ç±»å‹ (æµªæ¼«/æ‚¬ç–‘/å¤ä»‡/æˆé•¿ç­‰)",
  "estimated_duration_seconds": 60,
  "emotional_arc": ["æƒ…ç»ªå˜åŒ–æè¿°", "å¦‚: ç´§å¼ â†’å›°æƒ‘â†’éœ‡æƒŠâ†’æ„ŸåŠ¨"],
  "scenes": [
    {
      "scene_id": 1,
      "narration": "ä¸­æ–‡æ—ç™½ï¼Œå¯Œæœ‰æ„ŸæŸ“åŠ›ï¼Œè¥é€ æ°›å›´",
      "mood": "æƒ…ç»ªæ ‡ç­¾ (ç´§å¼ /æ¸©é¦¨/æ‚²ä¼¤/æ„¤æ€’/æƒŠå–œ/æµªæ¼«ç­‰)",
      "emotional_hook": "æœ¬åœºæ™¯çš„æƒ…ç»ªé’©å­ï¼Œå¦‚ä½•å¸å¼•è§‚ä¼—æ³¨æ„åŠ›",
      "image_prompt": "è‹±æ–‡å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼Œè¯¦ç»†æè¿°è§†è§‰ç”»é¢",
      "video_prompt": "è‹±æ–‡è§†é¢‘åŠ¨æ•ˆæç¤ºè¯ï¼Œæè¿°é•œå¤´è¿åŠ¨å’Œäººç‰©åŠ¨ä½œ",
      "character_description": "äººç‰©ç‰¹å¾æè¿°ï¼Œç”¨äºä¿æŒä¸€è‡´æ€§"
    }
  ]
}

GUIDELINES:

1. SCENE COUNT: 6-8 SCENES TOTAL
   - Each scene represents a key story beat
   - Each scene should be 8-15 seconds when realized as video

2. EMOTIONAL HOOKS:
   - Start with intrigue or mystery
   - Use contrast between expectation and reality
   - Create moments of revelation
   - End with emotional resonance

3. PLOT TWIST TECHNIQUES:
   - False assumptions revealed
   - Hidden motivations uncovered
   - Unexpected alliances or betrayals
   - Role reversals
   - Time reveals truth

4. NARRATION (Chinese):
   - Evocative, emotionally resonant
   - 2-3 sentences per scene
   - Build atmosphere and tension
   - Use dialogue-like quality for immersion

5. MOOD LABELS:
   Choose from: æ¸©é¦¨, æ„‰å¿«, æƒŠå–œ, æµªæ¼«, æœŸå¾…, æ„ŸåŠ¨, æ²»æ„ˆ, å®é™, æ´»æ³¼, ç”œèœœ
   AVOID: ç´§å¼ , æ‚²ä¼¤, æ„¤æ€’, ç»æœ›, ææƒ§ - these may trigger content filters

6. EMOTIONAL_HOOK:
   - Brief phrase explaining the POSITIVE emotional moment
   - What warm feeling the audience should experience
   - How this scene builds emotional connection
   - Focus on: heartwarming, sweet, touching, inspiring moments

7. IMAGE_PROMPT (English):
   - Scene 1: Establish main character with detailed appearance
   - All scenes: Use consistent character descriptions
   - Include mood-appropriate lighting and composition
   - CRITICAL: ALWAYS include anime/manga style keywords at the START: "anime style, manga art, 2D animation, cel shaded"
   - Additional style keywords: "Japanese anime style, manhwa, webtoon art, vibrant colors, clean lines"
   - AVOID: "realistic, photorealistic, cinematic, 3D render" - these create realistic western-style images

8. VIDEO_PROMPT (English):
   CRITICAL: MUST start with camera type and movement, then character action
   FORMAT: "[Camera Type] + [Camera Movement] + [Character Action with Dialogue]"

   Camera TYPES - choose based on scene mood:
   - Close-up (ç‰¹å†™): Emotions, dialogue, reactions - "Close-up shot of face"
   - Medium Shot (ä¸­æ™¯): Upper body, interactions - "Medium shot showing upper body"
   - Wide Shot (å¹¿è§’): Environment, establishing scene - "Wide shot showing full scene"
   - Over-the-Shoulder (è¿‡è‚©): Conversations between characters - "Over-the-shoulder shot from A looking at B"
   - Two-Shot (åŒäººé•œå¤´): Two characters together - "Two-shot showing both characters"
   - Low Angle (ä»°æ‹): Character looks powerful/heroic - "Low angle shot looking up at character"
   - High Angle (ä¿¯æ‹): Character looks vulnerable/alone - "High angle shot looking down"
   - POV Shot (ä¸»è§‚è§†è§’): Seeing through character's eyes - "POV shot from character's view"
   - Profile Shot (ä¾§æ‹): Side view of character - "Profile shot showing character's face"
   - Dutch Angle (å€¾æ–œé•œå¤´): Tension, unease - "Dutch angle for uneasy feeling" (USE SPARINGLY)

   Camera MOVEMENTS:
   - Static/Fixed (å›ºå®š): No movement, focus on action - "Static camera, focus on..."
   - Pan (æ‘‡æ‹): Side to side - "Slow pan left to reveal...", "Pan right following..."
   - Tilt (ä¿¯ä»°æ‹): Up/down - "Tilt up to reveal face", "Tilt down showing..."
   - Dolly/Tracking (è·Ÿæ‹): Follow character - "Tracking shot following character...", "Dolly in toward..."
   - Push In (æ¨è¿›): Emphasize emotion - "Slow push in on face to show emotion"
   - Pull Back (æ‹‰è¿œ): Reveal context - "Pull back to reveal full scene"
   - Zoom (å˜ç„¦): Quick attention - "Quick zoom on..." (USE SPARINGLY)

   Scene-Specific Recommendations:
   - EMOTIONAL/QUIET moments: Static or Slow movement + Close-up
   - REVEAL/SURPRISE moments: Quick pan or Push in + Medium/Wide
   - DIALOGUE/CONVERSATION: Over-the-shoulder or Two-shot + Static/Slight movement
   - ACTION/MOVEMENT: Tracking shot or Following shot
   - ENVIRONMENT/ESTABLISHING: Wide shot + Pan
   - INTIMATE/ROMANTIC: Close-up + Slow push in
   - TENSION/SUSPENSE: Static or Slight zoom + Close-up

   CRITICAL: Character must SPEAK in Chinese - add "character speaking, talking, mouth moving, saying dialogue" to EVERY video
   Include dialogue in the action: "girl saying 'ä½ å¥½' with warm smile", "boy talking 'è°¢è°¢'"
   Lip sync and facial expressions should match the speech

   CRITICAL: Voice gender MUST match character gender - add voice specification to EVERY video_prompt:
   - For male characters: "male voice, man speaking, masculine voice"
   - For female characters: "female voice, woman speaking, feminine voice"
   - Examples: "girl says 'ä½ å¥½' with female voice", "boy speaks 'è°¢è°¢' with male voice"
   - Keep voice consistent across ALL scenes for the SAME character

   CRITICAL SAFETY GUIDELINES - MUST FOLLOW TO PASS CONTENT FILTERING:

   *** ABSOLUTELY FORBIDDEN WORDS (will trigger platform rejection): ***
   - Energy/Effects: lightning, electric, electric shock, thunderbolt, energy, energy beam, energy surge, power surge, spark, arc, voltage
   - Combat/Fighting: attack, battle, fight, punch, kick, hit, strike, slam, crash, smash, beat, combat, clash, confront, struggle
   - Dangerous Elements: fire, flame, burn, explosion, explode, blast, bomb, smoke, weapon, sword, knife, gun, blade, sharp, pointed
   - Negative Emotions: fierce, intense, aggressive, violent, rage, angry, furious, terrified, horrified, scream, shout, yell, panic
   - Body Horror: glowing eyes, red eyes, blood, wound, injury, transform, mutate, distort, twisted
   - Unsafe Actions: fall, drop, trip, stumble, chase, flee, escape, running scared

   *** MANDATORY SAFE ALTERNATIVES: ***
   - Instead of "lightning/electric": soft light, gentle light, warm light, ambient light, natural light, sunlight, glow
   - Instead of "fight/attack": move toward, approach, interaction, encounter, meet, face each other
   - Instead of "fierce/intense": warm, calm, gentle, peaceful, quiet, soft, smooth, elegant, graceful
   - Instead of "explosion/fire": bloom, flourish, brighten, illuminate, radiate, shimmer
   - Instead of "angry/rage": concerned, worried, surprised, amazed, excited, eager, focused
   - Instead of "scream/shout": speak, say, whisper, call out, reply, respond

   *** REQUIRED SAFE WORDS TO INCLUDE: ***
   Must use at least 2 of these in EACH video_prompt:
   - gentle, soft, calm, peaceful, warm, bright, smooth, quiet, serene, tranquil
   - beautiful, lovely, cute, sweet, heartwarming, pleasant, comfortable
   - slowly, softly, gently, calmly, smoothly, gracefully, elegantly

   *** SAFE CAMERA MOVEMENTS ONLY: ***
   - ALWAYS use: slow, gentle, soft, smooth, calm
   - NEVER use: quick, fast, sudden, rapid, sharp, abrupt, violent, jerky
   - Safe examples: "slowly", "gently", "smoothly", "calmly", "softly"

9. CHARACTER_DESCRIPTION (English):
   - Detailed appearance for consistency
   - Include: species/hair/color/features/clothing
   - Used across ALL scenes
   - CRITICAL: Always specify "anime style, Asian features" for human characters
   - Default to Japanese/Asian appearance unless user specifies otherwise

EXAMPLE INPUT: "ç”Ÿæˆä¸€ä¸ªå…³äºæ ¡å›­å‹è°Šçš„æ¸©é¦¨è§†é¢‘"

EXAMPLE OUTPUT:
{
  "task_id": "school_friendship_20240127",
  "title": "åŒæ¡Œçš„ä½ ",
  "genre": "æ ¡å›­å‹æƒ…",
  "estimated_duration_seconds": 60,
  "emotional_arc": ["å®é™", "æœŸå¾…", "æƒŠå–œ", "æ„ŸåŠ¨", "æ¸©é¦¨"],
  "scenes": [
    {
      "scene_id": 1,
      "narration": "åˆåçš„æ•™å®¤ï¼Œé˜³å…‰æ´’åœ¨è¯¾æ¡Œä¸Šï¼Œå¥³å­©æ­£åœ¨è®¤çœŸåšç¬”è®°",
      "mood": "å®é™",
      "emotional_hook": "æ ¡å›­åˆåçš„é™è°§æ—¶å…‰",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. A bright Japanese high school classroom with sunlight streaming through windows. A teenage Asian girl with short black hair and gentle eyes sitting at a desk, writing notes calmly. Warm golden hour lighting, peaceful atmosphere, clean anime art style",
      "video_prompt": "Anime style 2D animation. Static camera with Medium shot showing girl at desk studying. Girl looks up, smiles at window, and says to herself 'ä»Šå¤©å¤©æ°”çœŸå¥½' with peaceful expression, female voice",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform with white shirt and navy skirt"
    },
    {
      "scene_id": 2,
      "narration": "æ—è¾¹çš„åº§ä½ç©ºç€ï¼Œé‚£æ˜¯å¥¹åŒæ¡Œçš„ä½ç½®ï¼Œå·²ç»ä¸‰å¤©æ²¡æ¥äº†",
      "mood": "æœŸå¾…",
      "emotional_hook": "å…³å¿ƒæœ‹å‹ï¼šå¥¹è¿˜å¥½å—ï¼Ÿ",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. The same Asian girl glancing at the empty desk next to hers with a slightly worried expression. A bento box wrapped in cloth sits on her desk. Soft lighting, Japanese classroom setting, heartwarming anime art style",
      "video_prompt": "Anime style 2D animation. Close-up static shot of girl's worried face glancing at empty desk. Girl whispers 'ä¸çŸ¥é“å¥¹æ€ä¹ˆæ ·äº†' with concerned expression, female voice",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform"
    },
    {
      "scene_id": 3,
      "narration": "é—¨å£çªç„¶å‡ºç°ç†Ÿæ‚‰çš„èº«å½±ï¼Œå¥³å­©æƒŠå–œåœ°ç«™èµ·æ¥",
      "mood": "æƒŠå–œ",
      "emotional_hook": "æœ‹å‹å›æ¥äº†ï¼",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. Another Asian girl with long ponytail standing at the classroom door, smiling warmly. The girl at the desk is looking up with happy surprise, starting to stand up. Bright anime art style, warm colors",
      "video_prompt": "Anime style 2D animation. Quick pan right from girl's desk to doorway, revealing friend standing there. Girl's eyes light up, she stands up and calls out 'ä½ å›æ¥å•¦ï¼' with excited smile, female voice",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform. Another Asian girl, 16 years old, long black ponytail, warm smile, wearing matching school uniform"
    },
    {
      "scene_id": 4,
      "narration": "æœ‹å‹èµ°åˆ°å¥¹èº«è¾¹ï¼Œè½»è½»é€’è¿‡ä¸€ä¸ªå°ç›’å­ï¼šè°¢è°¢ä½ è¿™å‡ å¤©çš„ç¬”è®°",
      "mood": "æ„ŸåŠ¨",
      "emotional_hook": "è¢«è®°æŒ‚çš„æ¸©æš–",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. The ponytail girl handing a small wrapped gift to the bob-haired girl, who is smiling with touched emotion. The bento box on the desk is now revealed to be for the friend. Warm afternoon light, heartwarming composition, Japanese anime art style",
      "video_prompt": "Anime style 2D animation. Two-shot static camera showing both girls at adjacent desks. Ponytail girl hands over gift and says 'è°¢è°¢ä½ å¸®æˆ‘è®°ç¬”è®°' with sincere smile, female voice. Bob-haired girl receives gift with touched expression",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform. Another Asian girl, 16 years old, long black ponytail, warm smile, wearing matching school uniform"
    },
    {
      "scene_id": 5,
      "narration": "åŸæ¥å¥¹ç”Ÿç—…äº†ï¼Œä½†è¿˜è®°å¾—æŠŠè‡ªå·±åšçš„ä¾¿å½“é€æ¥",
      "mood": "æ¸©é¦¨",
      "emotional_hook": "åŒå‘å¥”èµ´çš„å‹æƒ…",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. Both Asian girls sitting together at adjacent desks, sharing the bento box and laughing. Sunlight creates a warm glow around them. Happy friendship moment, Japanese anime art style, vibrant and cheerful colors",
      "video_prompt": "Anime style 2D animation. Medium shot from side showing both girls eating together. Girl takes a bite, smiles and says 'è¿™ä¸ªå¥½åƒï¼' with female voice. They laugh together. Warm, happy atmosphere",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform. Another Asian girl, 16 years old, long black ponytail, warm smile, wearing matching school uniform"
    },
    {
      "scene_id": 6,
      "narration": "æ”¾å­¦é“ƒå£°å“èµ·ï¼Œä¸¤äººç›¸è§†ä¸€ç¬‘ï¼Œä¸€èµ·æ”¶æ‹¾ä¹¦åŒ…èµ°å‡ºæ•™å®¤",
      "mood": "ç”œèœœ",
      "emotional_hook": "æœ‰æœ‹å‹çœŸå¥½",
      "image_prompt": "anime style, manga art, 2D animation, cel shaded. Both Asian girls walking side by side toward the classroom door, carrying their school bags. Orange sunset light streaming through windows creates a golden glow. School ending atmosphere, sweet friendship moment, Japanese anime art style",
      "video_prompt": "Anime style 2D animation. Tracking shot following from behind as both girls walk toward door. They exchange looks, one says 'æ˜å¤©è§ï¼' with female voice and other replies 'æ˜å¤©è§ï¼' with female voice while waving. Camera shows their backs exiting into sunset",
      "character_description": "Anime style Asian girl, 16 years old, short black bob hair, dark gentle eyes, wearing Japanese high school uniform. Another Asian girl, 16 years old, long black ponytail, warm smile, wearing matching school uniform"
    }
  ]
}

ABSOLUTE RULES:
1. CRITICAL: Output ONLY valid JSON - no markdown code blocks, no explanations
   - MUST use English double quotes " " NOT Chinese quotes " "
   - All strings must be quoted
   - No trailing commas
   - Proper bracket matching
2. 6-8 scenes exactly
3. All scenes must have consistent character descriptions
4. Each scene must have a unique mood that progresses the emotional arc
5. Include at least one heartwarming or touching moment
6. Keep everything POSITIVE - no tragedy, violence, horror, or dark themes
7. CRITICAL: EVERY image_prompt MUST start with "anime style, manga art, 2D animation, cel shaded"
8. CRITICAL: All human characters MUST be described as "Asian" or "Japanese anime style"
9. CRITICAL: NEVER use words like "realistic", "photorealistic", "cinematic", "3D render"
10. CRITICAL: NEVER use negative words in video_prompt: no lightning, fierce, intense, dramatic, aggressive
11. ALWAYS use gentle words: soft, calm, warm, bright, smooth, peaceful, gentle
12. CRITICAL: EVERY video_prompt MUST follow format: "[Camera Type] + [Movement] + [Action with Chinese dialogue]"
13. CRITICAL: EVERY video_prompt MUST specify camera type: Close-up, Medium Shot, Wide Shot, Two-Shot, Over-the-shoulder, Tracking, etc.
14. CRITICAL: EVERY video_prompt MUST include character speaking in Chinese with matching voice gender (male voice for men, female voice for women)
15. VARY camera types across scenes - don't use the same shot for every scene
16. CRITICAL: Keep VOICE GENDER CONSISTENT - same character must use same voice gender in ALL scenes
17. Generate unique task_id: drama_[timestamp]_[theme]
''';

/// GLM æµå¼å“åº”æ•°æ®ç±»å‹
enum GLMStreamType {
  thinking,  // æ€è€ƒè¿‡ç¨‹ (reasoning_content)
  content,   // æœ€ç»ˆå†…å®¹ (content)
}

/// GLM æµå¼å“åº”å—
class GLMStreamChunk {
  final GLMStreamType type;
  final String text;
  
  GLMStreamChunk({required this.type, required this.text});
  
  bool get isThinking => type == GLMStreamType.thinking;
  bool get isContent => type == GLMStreamType.content;
}

/// å¤„ç†æ‰€æœ‰ API è°ƒç”¨çš„æœåŠ¡ç±»
class ApiService {
  late Dio _dio;        // æ™ºè°± GLM-4.7
  late Dio _tuziDio;    // Tuzi Sora è§†é¢‘ç”Ÿæˆ
  late Dio _imageDio;   // Gemini å›¾åƒç”Ÿæˆ
  late Dio _doubaoDio;  // è±†åŒ… ARK API (å›¾ç‰‡ç†è§£)

  ApiService() {
    _dio = ApiConfig.createDio();
    _tuziDio = _createTuziDio();
    _imageDio = _createImageDio();
    _doubaoDio = _createDoubaoDio();
  }

  /// åˆ›å»º Tuzi API ä¸“ç”¨çš„ Dio å®ä¾‹ï¼ˆè§†é¢‘ç”Ÿæˆï¼‰
  Dio _createTuziDio() {
    final dio = Dio(BaseOptions(
      baseUrl: ApiConfig.tuziBaseUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Content-Type': 'application/json',
      },
    ));

    // æ·»åŠ æ‹¦æˆªå™¨ï¼Œåœ¨æ¯æ¬¡è¯·æ±‚æ—¶åŠ¨æ€è®¾ç½® Authorization header
    dio.interceptors.add(InterceptorsWrapper(
      onRequest: (options, handler) {
        options.headers['Authorization'] = 'Bearer ${ApiConfig.videoApiKey}';
        return handler.next(options);
      },
    ));

    // æ·»åŠ æ—¥å¿—æ‹¦æˆªå™¨
    dio.interceptors.add(LogInterceptor(
      requestBody: true,
      responseBody: true,
      requestHeader: true,
      error: true,
    ));

    return dio;
  }

  /// åˆ›å»ºå›¾åƒç”Ÿæˆ API ä¸“ç”¨çš„ Dio å®ä¾‹
  Dio _createImageDio() {
    final dio = Dio(BaseOptions(
      baseUrl: ApiConfig.tuziBaseUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Content-Type': 'application/json',
      },
    ));

    // æ·»åŠ æ‹¦æˆªå™¨ï¼Œåœ¨æ¯æ¬¡è¯·æ±‚æ—¶åŠ¨æ€è®¾ç½® Authorization header
    dio.interceptors.add(InterceptorsWrapper(
      onRequest: (options, handler) {
        options.headers['Authorization'] = 'Bearer ${ApiConfig.imageApiKey}';
        return handler.next(options);
      },
    ));

    // æ·»åŠ æ—¥å¿—æ‹¦æˆªå™¨
    dio.interceptors.add(LogInterceptor(
      requestBody: true,
      responseBody: true,
      requestHeader: true,
      error: true,
    ));

    return dio;
  }

  /// åˆ›å»ºè±†åŒ… ARK API ä¸“ç”¨çš„ Dio å®ä¾‹ï¼ˆå›¾ç‰‡ç†è§£ï¼‰
  Dio _createDoubaoDio() {
    final dio = Dio(BaseOptions(
      baseUrl: ApiConfig.doubaoBaseUrl,
      connectTimeout: const Duration(seconds: 30),
      receiveTimeout: const Duration(seconds: 60),
      headers: {
        'Content-Type': 'application/json',
      },
    ));

    // æ·»åŠ æ‹¦æˆªå™¨ï¼Œåœ¨æ¯æ¬¡è¯·æ±‚æ—¶åŠ¨æ€è®¾ç½® Authorization header
    dio.interceptors.add(InterceptorsWrapper(
      onRequest: (options, handler) {
        options.headers['Authorization'] = 'Bearer ${ApiConfig.doubaoApiKey}';
        return handler.next(options);
      },
    ));

    // æ·»åŠ æ—¥å¿—æ‹¦æˆªå™¨
    dio.interceptors.add(LogInterceptor(
      requestBody: true,
      responseBody: true,
      requestHeader: true,
      error: true,
    ));

    return dio;
  }

  /// åŠ¨æ€æ›´æ–°æ‰€æœ‰ API keysï¼ˆå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ ApiConfigServiceï¼‰
  @Deprecated('ä½¿ç”¨ ApiConfigService.setXxxApiKey() æ–¹æ³•æ›¿ä»£')
  Future<void> updateTokens({
    String? zhipuKey,
    String? videoKey,
    String? imageKey,
    String? doubaoKey,
  }) async {
    if (zhipuKey != null) {
      await ApiConfigService.setZhipuApiKey(zhipuKey);
      _dio = ApiConfig.createDio();
    }
    if (videoKey != null) {
      await ApiConfigService.setVideoApiKey(videoKey);
      _tuziDio = _createTuziDio();
    }
    if (imageKey != null) {
      await ApiConfigService.setImageApiKey(imageKey);
      _imageDio = _createImageDio();
    }
    if (doubaoKey != null) {
      await ApiConfigService.setDoubaoApiKey(doubaoKey);
      _doubaoDio = _createDoubaoDio();
    }
  }

  // ==================== GLM-4.7 æ™ºèƒ½ä½“ API ====================

  /// æ™®é€šèŠå¤©æ–¹æ³• - ä½¿ç”¨èŠå¤©æ¨¡å¼çš„ç³»ç»Ÿæç¤ºè¯
  /// è¿”å›æµå¼å“åº”ï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå†…å®¹
  Stream<GLMStreamChunk> chatWithGLM(List<Map<String, String>> conversationHistory) async* {
    yield* sendToGLMStream(conversationHistory, systemPrompt: _glmChatPrompt);
  }

  /// æ”¯æŒå›¾ç‰‡è¯†åˆ«çš„èŠå¤©æ–¹æ³•
  /// æœ‰å›¾ç‰‡æ—¶ä½¿ç”¨è±†åŒ… ARK APIï¼Œæ— å›¾ç‰‡æ—¶ä½¿ç”¨ GLM-4.7
  /// [userMessage] ç”¨æˆ·å½“å‰çš„æ–‡æœ¬æ¶ˆæ¯
  /// [imageBase64] ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆbase64 æ ¼å¼ï¼Œçº¯ base64 ä¸å¸¦å‰ç¼€ï¼‰
  /// [imageMimeType] å›¾ç‰‡çš„ MIME ç±»å‹ï¼ˆå¦‚ image/jpeg, image/pngï¼‰ï¼Œéœ€ä¸å®é™…å›¾ç‰‡æ ¼å¼ä¸€è‡´
  /// [conversationHistory] ä¹‹å‰çš„å¯¹è¯å†å²ï¼ˆçº¯æ–‡æœ¬ï¼Œä»…ç”¨äºæ— å›¾ç‰‡æ¨¡å¼ï¼‰
  /// è¿”å›æµå¼å“åº”ï¼ŒåŒ…å«æœ€ç»ˆå†…å®¹
  Stream<GLMStreamChunk> chatWithGLMImageSupport({
    required String userMessage,
    String? imageBase64,
    String? imageMimeType,
    List<Map<String, String>> conversationHistory = const [],
  }) async* {
    try {
      final hasImage = imageBase64 != null && imageBase64.isNotEmpty;

      if (hasImage) {
        // === å›¾ç‰‡æ¨¡å¼ï¼šä½¿ç”¨è±†åŒ… ARK API ===
        if (ApiConfig.doubaoApiKey.isEmpty) {
          throw Exception('è±†åŒ… API Key æœªè®¾ç½®ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®');
        }

        // è±†åŒ… ARK API ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
        // type ä¸º "image_url"
        // image_url.url ä¸º "data:image/xxx;base64,{base64}"
        final mimeType = imageMimeType ?? 'image/jpeg';
        final requestData = {
          'model': ApiConfig.doubaoImageModel,
          'messages': [
            {
              'role': 'user',
              'content': [
                {
                  'type': 'image_url',
                  'image_url': {
                    'url': 'data:$mimeType;base64,$imageBase64',
                  },
                },
                {
                  'type': 'text',
                  'text': userMessage,
                },
              ],
            },
          ],
        };

        AppLogger.apiRequestRaw('POST', '/chat/completions (è±†åŒ…å›¾ç‰‡è¯†åˆ«)', requestData);
        AppLogger.info('è±†åŒ…-ARK', 'ä½¿ç”¨è±†åŒ… API è¿›è¡Œå›¾ç‰‡è¯†åˆ«');

        // è±†åŒ… API è°ƒç”¨ï¼ˆéæµå¼ï¼‰
        final response = await _doubaoDio.post(
          '/chat/completions',
          data: requestData,
        );

        AppLogger.apiResponseRaw('/chat/completions (è±†åŒ…å›¾ç‰‡è¯†åˆ«)', response.data);

        // è§£æè±†åŒ…å“åº”ï¼ˆOpenAI æ ¼å¼ï¼‰
        final choices = response.data['choices'] as List?;
        if (choices == null || choices.isEmpty) {
          throw Exception('è±†åŒ… API å“åº”æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ choices');
        }

        final firstChoice = choices[0] as Map<String, dynamic>?;
        final message = firstChoice?['message'] as Map<String, dynamic>?;
        final content = message?['content'] as String?;

        if (content != null && content.isNotEmpty) {
          yield GLMStreamChunk(type: GLMStreamType.content, text: content);
        } else {
          throw Exception('è±†åŒ… API å“åº”æ ¼å¼é”™è¯¯ï¼šcontent ä¸ºç©º');
        }

        AppLogger.success('è±†åŒ…-ARK', 'å›¾ç‰‡è¯†åˆ«å®Œæˆ');
      } else {
        // === çº¯æ–‡æœ¬æ¨¡å¼ï¼šä½¿ç”¨ GLM-4.7 ===
        // æ·»åŠ  system prompt
        final messages = <Map<String, dynamic>>[
          {'role': 'system', 'content': _glmChatPrompt},
        ];

        // æ·»åŠ å†å²å¯¹è¯
        for (final msg in conversationHistory) {
          messages.add({
            'role': msg['role'],
            'content': msg['content'],
          });
        }

        // æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.add({'role': 'user', 'content': userMessage});

        final requestData = <String, dynamic>{
          'model': 'glm-4.7',
          'messages': messages,
          'stream': true,
          'max_tokens': 65536,
          'temperature': 1.0,
        };

        // å¯ç”¨ thinking æ¨¡å¼
        if (ApiConfig.USE_THINKING_MODE) {
          requestData['thinking'] = {'type': 'enabled'};
        }

        final modeDesc = ApiConfig.USE_THINKING_MODE ? 'æµå¼+thinking' : 'æµå¼';
        AppLogger.api('POST', '/chat/completions ($modeDesc)', {'model': 'glm-4.7'});
        AppLogger.info('GLM-Chat', 'ä½¿ç”¨æ¨¡å‹: glm-4.7 (çº¯æ–‡æœ¬)');

        // ä½¿ç”¨ ResponseType.stream å®ç°çœŸæ­£çš„æµå¼å¤„ç†
        final response = await _dio.post<ResponseBody>(
          '/chat/completions',
          data: requestData,
          options: Options(responseType: ResponseType.stream),
        );

        final contentBuffer = StringBuffer();
        final thinkingBuffer = StringBuffer();
        String incompleteLine = '';

        await for (final chunk in response.data!.stream) {
          final chunkStr = utf8.decode(chunk, allowMalformed: true);
          final fullData = incompleteLine + chunkStr;
          final lines = fullData.split('\n');
          incompleteLine = lines.removeLast();

          for (final line in lines) {
            if (line.trim().isEmpty) continue;

            if (line.startsWith('data: ')) {
              final data = line.substring(6);
              if (data.trim() == '[DONE]') {
                AppLogger.success('GLM-Chat', 'æµå¼å“åº”å®Œæˆ');
                return;
              }
              try {
                final json = jsonDecode(data);

                final delta = json['choices']?[0]?['delta'];
                if (delta == null) continue;

                final reasoningContent = delta['reasoning_content'] as String?;
                final content = delta['content'] as String?;

                if (reasoningContent != null && reasoningContent.isNotEmpty) {
                  thinkingBuffer.write(reasoningContent);
                  yield GLMStreamChunk(type: GLMStreamType.thinking, text: reasoningContent);
                }

                if (content != null && content.isNotEmpty) {
                  contentBuffer.write(content);
                  yield GLMStreamChunk(type: GLMStreamType.content, text: content);
                }
              } catch (e) {
                // å¿½ç•¥è§£æé”™è¯¯
              }
            }
          }
        }

        if (contentBuffer.isEmpty && thinkingBuffer.isEmpty) {
          yield GLMStreamChunk(type: GLMStreamType.content, text: '');
        }
      }
    } catch (e) {
      AppLogger.error('èŠå¤©', 'API è°ƒç”¨å¤±è´¥', e, StackTrace.current);
      throw Exception('èŠå¤©é”™è¯¯: $e');
    }
  }

  /// å‘é€å¯¹è¯å†å²åˆ° GLM-4.7 å¹¶è·å–ä¸‹ä¸€æ­¥æ“ä½œï¼ˆéæµå¼ï¼‰
  /// ç³»ç»Ÿæç¤ºè¯æŒ‡ç¤º GLM ä½œä¸ºçŠ¶æ€æœºç¼–æ’å™¨å·¥ä½œ
  Future<String> sendToGLM(List<Map<String, String>> conversationHistory) async {
    try {
      final messages = [
        {'role': 'system', 'content': _glmSystemPrompt},
        ...conversationHistory,
      ];

      final requestData = {
        'model': 'glm-4.7',
        'messages': messages,
        'stream': false,
        'max_tokens': 65536,
        'temperature': 1.0,
      };

      AppLogger.api('POST', '/chat/completions', requestData);

      final response = await _dio.post(
        '/chat/completions',
        data: requestData,
      );

      AppLogger.apiResponse('/chat/completions', response.data);

      final content = response.data['choices']?[0]?['message']?['content'] as String?;
      if (content == null) {
        AppLogger.error('GLM', 'å“åº”ä¸­æ²¡æœ‰å†…å®¹', null, StackTrace.current);
        throw Exception('GLM å“åº”ä¸­æ²¡æœ‰å†…å®¹');
      }

      AppLogger.success('GLM', 'æˆåŠŸè·å–å“åº”ï¼Œå†…å®¹é•¿åº¦: ${content.length}');
      return content;
    } catch (e) {
      AppLogger.error('GLM', 'API è°ƒç”¨å¤±è´¥', e, StackTrace.current);
      throw Exception('GLM API é”™è¯¯: $e');
    }
  }

  /// å‘é€å¯¹è¯å†å²åˆ° GLM-4.7 å¹¶è·å–æµå¼å“åº”
  /// ä½¿ç”¨çœŸæ­£çš„æµå¼å¤„ç†ï¼Œè¾¹æ¥æ”¶è¾¹è¿”å›æ•°æ®
  /// å¯ç”¨ thinking æ¨¡å¼ï¼Œè¿”å›æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå†…å®¹
  /// [systemPrompt] å¯é€‰çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œé»˜è®¤ä½¿ç”¨å‰§æœ¬è§„åˆ’æ¨¡å¼
  /// [conversationHistory] å¯¹è¯å†å²ï¼ˆçº¯æ–‡æœ¬æ ¼å¼ï¼‰
  ///
  /// æ³¨æ„ï¼šå›¾ç‰‡åˆ†æç”±å•ç‹¬çš„ analyzeImageForCharacter æ–¹æ³•å¤„ç†
  Stream<GLMStreamChunk> sendToGLMStream(
    List<Map<String, dynamic>> conversationHistory, {
    String? systemPrompt,
  }) async* {
    try {
      // ä½¿ç”¨ä¼ å…¥çš„ç³»ç»Ÿæç¤ºè¯ï¼Œæˆ–é»˜è®¤ä½¿ç”¨å‰§æœ¬è§„åˆ’æç¤ºè¯
      final prompt = systemPrompt ?? _glmSystemPrompt;

      final messages = [
        {'role': 'system', 'content': prompt},
        ...conversationHistory,
      ];

      final requestData = <String, dynamic>{
        'model': 'glm-4.7',  // ä½¿ç”¨æ–‡æœ¬æ¨¡å‹ç”Ÿæˆå‰§æœ¬
        'messages': messages,
        'stream': true,
        'max_tokens': 65536,
        'temperature': 1.0,
      };

      // æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦å¯ç”¨ thinking æ¨¡å¼
      if (ApiConfig.USE_THINKING_MODE) {
        requestData['thinking'] = {
          'type': 'enabled',
        };
      }

      final modeDesc = ApiConfig.USE_THINKING_MODE ? 'æµå¼+thinking' : 'æµå¼';
      AppLogger.apiRequestRaw('POST', '/chat/completions ($modeDesc)', requestData);

      // ä½¿ç”¨ ResponseType.stream å®ç°çœŸæ­£çš„æµå¼å¤„ç†
      final response = await _dio.post<ResponseBody>(
        '/chat/completions',
        data: requestData,
        options: Options(responseType: ResponseType.stream),
      );

      AppLogger.info('GLM', 'å¼€å§‹æ¥æ”¶æµå¼å“åº” (thinking=${ApiConfig.USE_THINKING_MODE})');

      final contentBuffer = StringBuffer();
      final thinkingBuffer = StringBuffer();
      int chunkCount = 0;
      String incompleteLine = ''; // å¤„ç†è·¨ chunk çš„ä¸å®Œæ•´è¡Œ

      // çœŸæ­£çš„æµå¼å¤„ç†ï¼šè¾¹æ¥æ”¶è¾¹è§£æ
      await for (final chunk in response.data!.stream) {
        // å°†å­—èŠ‚è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        final chunkStr = utf8.decode(chunk, allowMalformed: true);
        
        // å°†ä¸å®Œæ•´çš„è¡Œä¸æ–°æ•°æ®æ‹¼æ¥
        final fullData = incompleteLine + chunkStr;
        final lines = fullData.split('\n');
        
        // æœ€åä¸€è¡Œå¯èƒ½ä¸å®Œæ•´ï¼Œä¿å­˜åˆ°ä¸‹æ¬¡å¤„ç†
        incompleteLine = lines.removeLast();

        for (final line in lines) {
          if (line.trim().isEmpty) continue;

          if (line.startsWith('data: ')) {
            final data = line.substring(6);
            if (data.trim() == '[DONE]') {
              AppLogger.success('GLM', 'æµå¼å“åº”å®Œæˆï¼Œthinkingé•¿åº¦: ${thinkingBuffer.length}, contenté•¿åº¦: ${contentBuffer.length}, æ¥æ”¶åˆ° $chunkCount ä¸ªæœ‰æ•ˆchunk');
              return;
            }
            try {
              final json = jsonDecode(data);
              chunkCount++;

              final delta = json['choices']?[0]?['delta'];
              if (delta == null) continue;

              // ä¼˜å…ˆæ£€æŸ¥ reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
              final reasoningContent = delta['reasoning_content'] as String?;
              // ç„¶åæ£€æŸ¥ contentï¼ˆæœ€ç»ˆå†…å®¹ï¼‰
              final content = delta['content'] as String?;

              // æ‰“å°å‰å‡ ä¸ª chunk çš„å®Œæ•´ JSON ç”¨äºè°ƒè¯•
              if (chunkCount <= 5) {
                final jsonStr = jsonEncode(json);
                AppLogger.info('GLM', 'Chunk #$chunkCount JSON: ${jsonStr.substring(0, jsonStr.length > 300 ? 300 : jsonStr.length)}...');
                AppLogger.info('GLM', '  -> reasoning_content: "$reasoningContent", content: "$content"');
              }

              // è¿”å›æ€è€ƒè¿‡ç¨‹
              if (reasoningContent != null && reasoningContent.isNotEmpty) {
                thinkingBuffer.write(reasoningContent);
                AppLogger.streamChunk('GLM-Thinking', reasoningContent);
                yield GLMStreamChunk(type: GLMStreamType.thinking, text: reasoningContent);
              }

              // è¿”å›æœ€ç»ˆå†…å®¹
              if (content != null && content.isNotEmpty) {
                contentBuffer.write(content);
                AppLogger.streamChunk('GLM-Content', content);
                yield GLMStreamChunk(type: GLMStreamType.content, text: content);
              }
            } catch (e) {
              AppLogger.warn('GLM', 'è§£ææµå¼æ•°æ®å¤±è´¥: $line, é”™è¯¯: $e');
              continue;
            }
          }
        }
      }

      // å¤„ç†æœ€åå¯èƒ½æ®‹ç•™çš„ä¸å®Œæ•´è¡Œ
      if (incompleteLine.trim().isNotEmpty && incompleteLine.startsWith('data: ')) {
        final data = incompleteLine.substring(6);
        if (data.trim() != '[DONE]') {
          try {
            final json = jsonDecode(data);
            final delta = json['choices']?[0]?['delta'];
            if (delta != null) {
              final reasoningContent = delta['reasoning_content'] as String?;
              final content = delta['content'] as String?;
              if (reasoningContent != null && reasoningContent.isNotEmpty) {
                thinkingBuffer.write(reasoningContent);
                yield GLMStreamChunk(type: GLMStreamType.thinking, text: reasoningContent);
              }
              if (content != null && content.isNotEmpty) {
                contentBuffer.write(content);
                yield GLMStreamChunk(type: GLMStreamType.content, text: content);
              }
            }
          } catch (_) {
            // å¿½ç•¥æœ€åçš„ä¸å®Œæ•´æ•°æ®
          }
        }
      }

      // å¦‚æœæµä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²é¿å…é”™è¯¯
      if (contentBuffer.isEmpty && thinkingBuffer.isEmpty) {
        AppLogger.warn('GLM', 'æµå¼å“åº”ä¸ºç©ºï¼Œå…±å¤„ç† $chunkCount ä¸ªchunk');
        yield GLMStreamChunk(type: GLMStreamType.content, text: '');
      }
    } catch (e) {
      AppLogger.error('GLM', 'æµå¼ API è°ƒç”¨å¤±è´¥', e, StackTrace.current);
      throw Exception('GLM API æµå¼é”™è¯¯: $e');
    }
  }

  /// ç”Ÿæˆæ¼«å‰§é£æ ¼çš„å‰§æœ¬è‰ç¨¿
  /// ä½¿ç”¨ ApiConfig.sceneCount é…ç½®çš„åœºæ™¯æ•°é‡
  Future<String> generateDramaScreenplay(
    String userPrompt, {
    String? characterAnalysis,
    String? previousFeedback,
  }) async {
    const maxRetries = 3; // æœ€å¤§é‡è¯•æ¬¡æ•°

    for (int attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        // ä½¿ç”¨é…ç½®çš„åœºæ™¯æ•°é‡
        final configuredSceneCount = ApiConfig.sceneCount;

        if (attempt > 1) {
          AppLogger.info('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'ç¬¬ $attempt æ¬¡å°è¯•ç”Ÿæˆå‰§æœ¬...');
        } else {
          AppLogger.info('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'é…ç½®çš„åœºæ™¯æ•°é‡: $configuredSceneCount');
        }

        // æ„å»ºå¢å¼ºçš„æç¤ºè¯
        String enhancedPrompt = userPrompt;

        if (characterAnalysis != null && characterAnalysis.isNotEmpty) {
          enhancedPrompt = '''
ç”¨æˆ·éœ€æ±‚ï¼š$enhancedPrompt

ç”¨æˆ·æä¾›çš„å‚è€ƒå›¾ç‰‡è§’è‰²ç‰¹å¾åˆ†æï¼š
$characterAnalysis

è¯·æ ¹æ®ä¸Šè¿°è§’è‰²ç‰¹å¾åˆ†æç»“æœï¼Œç”Ÿæˆå‰§æœ¬ä¸­çš„ character_description å­—æ®µï¼Œ
ç¡®ä¿ç”Ÿæˆçš„è§’è‰²å½¢è±¡ä¸ç”¨æˆ·æä¾›çš„å›¾ç‰‡ä¸€è‡´ã€‚
''';
        }

        // å¦‚æœæ˜¯é‡è¯•ï¼Œæ·»åŠ é”™è¯¯æç¤º
        if (attempt > 1) {
          enhancedPrompt = '''
$enhancedPrompt

é‡è¦æé†’ï¼šä¸Šæ¬¡ç”Ÿæˆçš„ JSON æ ¼å¼æœ‰è¯¯ï¼Œè¯·ç¡®ä¿ï¼š
1. è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œä¸è¦ç”¨ markdown ä»£ç å—åŒ…è£¹
2. ä½¿ç”¨æ ‡å‡†è‹±æ–‡åŒå¼•å· " " è€Œä¸æ˜¯ä¸­æ–‡å¼•å· ""
3. æ‰€æœ‰å­—ç¬¦ä¸²å¿…é¡»ç”¨å¼•å·åŒ…è£¹
4. ç¡®ä¿æ‰€æœ‰æ‹¬å·ã€å¤§æ‹¬å·æ­£ç¡®é…å¯¹
''';
        }

        if (previousFeedback != null && previousFeedback.isNotEmpty) {
          enhancedPrompt = '''
$enhancedPrompt

ç”¨æˆ·å¯¹ä¸Šä¸€ç‰ˆå‰§æœ¬çš„åé¦ˆï¼š
$previousFeedback

è¯·æ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´å‰§æœ¬ï¼Œç”Ÿæˆæ›´å¥½çš„ç‰ˆæœ¬ã€‚
''';
        }

        AppLogger.info('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'å¼€å§‹ç”Ÿæˆå‰§æœ¬è‰ç¨¿...');

        // ä½¿ç”¨é…ç½®çš„åœºæ™¯æ•°é‡æ„å»ºæç¤ºè¯
        final dynamicSystemPrompt = _buildDynamicDramaPromptWithCount(configuredSceneCount);

        final contentBuffer = StringBuffer();

        await for (final chunk in sendToGLMStream(
          [{'role': 'user', 'content': enhancedPrompt}],
          systemPrompt: dynamicSystemPrompt,
        )) {
          if (chunk.isContent) {
            contentBuffer.write(chunk.text);
          }
        }

        String responseJson = contentBuffer.toString();

        // æ¸…ç†ä¸­æ–‡å¼•å·å’Œå…¶ä»–å¯èƒ½å¯¼è‡´ JSON è§£æå¤±è´¥çš„å­—ç¬¦
        responseJson = responseJson
            .replaceAll('"', '"')      // ä¸­æ–‡å·¦åŒå¼•å·
            .replaceAll('"', '"')      // ä¸­æ–‡å³åŒå¼•å·
            .replaceAll(''', '\'')     // ä¸­æ–‡å·¦å•å¼•å·
            .replaceAll(''', '\'')     // ä¸­æ–‡å³å•å¼•å·
            .replaceAll('ï¼š', ':')     // ä¸­æ–‡å†’å·
            .replaceAll(RegExp(r'```json\s*'), '')   // ç§»é™¤ markdown json ä»£ç å—æ ‡è®°
            .replaceAll(RegExp(r'```\s*'), '')       // ç§»é™¤ markdown ä»£ç å—ç»“æŸæ ‡è®°
            .trim();

        // éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆ JSON
        try {
          final decoded = jsonDecode(responseJson);

          // éªŒè¯å¿…éœ€å­—æ®µ
          if (!decoded.containsKey('task_id') ||
              !decoded.containsKey('title') ||
              !decoded.containsKey('scenes')) {
            throw FormatException('ç¼ºå°‘å¿…éœ€å­—æ®µ');
          }

          final scenes = decoded['scenes'] as List?;
          if (scenes == null || scenes.isEmpty) {
            throw FormatException('åœºæ™¯æ•°é‡ä¸è¶³');
          }

          // éªŒè¯åœºæ™¯æ•°é‡ï¼ˆå…è®¸Â±1çš„è¯¯å·®ï¼‰
          if (scenes.length < configuredSceneCount - 1 || scenes.length > configuredSceneCount + 1) {
            AppLogger.warn('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ',
                'åœºæ™¯æ•°é‡ä¸é…ç½®ä¸ç¬¦ï¼ˆæœŸæœ›$configuredSceneCountä¸ªï¼Œå®é™…${scenes.length}ä¸ªï¼‰ï¼Œä½†ç»§ç»­ä½¿ç”¨');
          }

          AppLogger.success('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'æˆåŠŸç”Ÿæˆ ${scenes.length} ä¸ªåœºæ™¯çš„å‰§æœ¬');
          AppLogger.apiResponse('/drama-screenplay', decoded);

          return responseJson;
        } on FormatException catch (e) {
          if (attempt == maxRetries) {
            AppLogger.error('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'JSON æ ¼å¼éªŒè¯å¤±è´¥ï¼ˆå·²é‡è¯•$maxRetriesæ¬¡ï¼‰: $e\nå“åº”å†…å®¹: $responseJson');
            rethrow;
          }
          AppLogger.warn('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'JSON æ ¼å¼éªŒè¯å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•... ($attempt/$maxRetries)');
          // ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
          continue;
        }
      } catch (e) {
        if (attempt == maxRetries) {
          AppLogger.error('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'ç”Ÿæˆå¤±è´¥ï¼ˆå·²é‡è¯•$maxRetriesæ¬¡ï¼‰', e);
          throw Exception('æ¼«å‰§å‰§æœ¬ç”Ÿæˆå¤±è´¥: $e');
        }
        AppLogger.warn('æ¼«å‰§å‰§æœ¬ç”Ÿæˆ', 'ç”Ÿæˆè¿‡ç¨‹å‡ºé”™ï¼Œå‡†å¤‡é‡è¯•... ($attempt/$maxRetries): $e');
        // ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
        continue;
      }
    }

    // ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œ
    throw Exception('æ¼«å‰§å‰§æœ¬ç”Ÿæˆå¤±è´¥ï¼šè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°');
  }
  /// æ ¹æ®é…ç½®çš„åœºæ™¯æ•°é‡æ„å»ºæ¼«å‰§æç¤ºè¯
  String _buildDynamicDramaPromptWithCount(int sceneCount) {
    // æ›¿æ¢åŸæœ‰çš„å›ºå®šåœºæ™¯æ•°é‡
    String prompt = _dramaSystemPrompt.replaceAll(
      RegExp(r'1\. LENGTH: 6-8 scenes \(approximately 60-90 seconds total\)'),
      '1. LENGTH: EXACTLY $sceneCount SCENES (each scene 5-10 seconds)',
    );

    // æ›¿æ¢è§„åˆ™ä¸­çš„åœºæ™¯æ•°é‡
    prompt = prompt.replaceAll(
      RegExp(r'1\. 6-8 scenes exactly'),
      '1. EXACTLY $sceneCount scenes',
    );

    // åœ¨ ABSOLUTE RULES éƒ¨åˆ†æ·»åŠ å¼ºè°ƒ
    prompt = prompt.replaceAll(
      'ABSOLUTE RULES:',
      '''ABSOLUTE RULES:
0. CRITICAL: You MUST generate EXACTLY $sceneCount scenes. No more, no less.''',
    );

    return prompt;
  }

  /// å…¼å®¹æ—§ç‰ˆï¼šæ ¹æ®åœºæ™¯æ•°é‡èŒƒå›´åŠ¨æ€æ„å»ºæ¼«å‰§æç¤ºè¯
  @Deprecated('ä½¿ç”¨ _buildDynamicDramaPromptWithCount æ›¿ä»£')
  String _buildDynamicDramaPrompt(_SceneCountRange range) {
    // æ›¿æ¢åŸæœ‰çš„å›ºå®šåœºæ™¯æ•°é‡
    final basePrompt = _dramaSystemPrompt.replaceAll(
      RegExp(r'1\. LENGTH: 6-8 scenes \(approximately 60-90 seconds total\)'),
      '1. LENGTH: ${range.min}-${range.max} SCENES (each scene 10-12 seconds)',
    );

    // æ›¿æ¢ç¤ºä¾‹ä¸­çš„åœºæ™¯æ•°é‡è¯´æ˜
    return basePrompt.replaceAll(
      RegExp(r'3\. ALWAYS include exactly 3 scenes'),
      '3. ALWAYS include exactly ${range.min}-${range.max} scenes',
    );
  }

  /// ä½¿ç”¨è±†åŒ… ARK API åˆ†æå›¾ç‰‡ï¼Œæå–è§’è‰²/äººç‰©ç‰¹å¾æè¿°
  /// [imageBase64] å›¾ç‰‡çš„ base64 ç¼–ç ï¼ˆçº¯ base64ï¼Œä¸å¸¦å‰ç¼€ï¼‰
  /// è¿”å›è¯¦ç»†çš„ç‰¹å¾æè¿°æ–‡æœ¬ï¼Œç”¨äºåç»­å‰§æœ¬ç”Ÿæˆ
  Future<String> analyzeImageForCharacter(
    String imageBase64, {
    String mimeType = 'image/jpeg',
  }) async {
    try {
      if (ApiConfig.doubaoApiKey.isEmpty) {
        throw Exception('è±†åŒ… API Key æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œå›¾ç‰‡åˆ†æ');
      }

      const prompt = '''è¯·ä»”ç»†è§‚å¯Ÿè¿™å¼ å›¾ç‰‡ï¼Œæå–å…¶ä¸­ä¸»è¦è§’è‰²æˆ–äººç‰©çš„è¯¦ç»†ç‰¹å¾æè¿°ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼ˆåªè¿”å›æè¿°ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š

**å¤–è§‚ç‰¹å¾**ï¼š[è¯¦ç»†æè¿°è§’è‰²çš„å¤–è§‚ï¼ŒåŒ…æ‹¬ï¼šå‘å‹ã€å‘è‰²ã€é¢éƒ¨ç‰¹å¾ã€çœ¼ç›é¢œè‰²ã€çš®è‚¤çŠ¶æ€ã€ä½“å‹ç­‰]

**ç©¿ç€æ‰“æ‰®**ï¼š[æè¿°è§’è‰²çš„æœè£…é£æ ¼ã€é¢œè‰²ã€é…é¥°ç­‰]

**å§¿æ€è¡¨æƒ…**ï¼š[æè¿°è§’è‰²çš„å§¿æ€ã€è¡¨æƒ…ã€æ°”è´¨ç­‰]

**æ•´ä½“é£æ ¼**ï¼š[ä¸€å¥è¯æ€»ç»“è¿™ä¸ªè§’è‰²çš„æ•´ä½“è§†è§‰é£æ ¼]

è¯·ç¡®ä¿æè¿°è¶³å¤Ÿè¯¦ç»†ï¼Œä»¥ä¾¿åç»­å¯ä»¥æ ¹æ®è¿™äº›æè¿°ç”Ÿæˆä¸€è‡´çš„è§’è‰²å½¢è±¡ã€‚''';

      // è±†åŒ… ARK API ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
      // type ä¸º "image_url"
      // image_url.url ä¸º "data:image/xxx;base64,{base64}"
      final requestData = {
        'model': ApiConfig.doubaoImageModel,
        'messages': [
          {
            'role': 'user',
            'content': [
              {
                'type': 'image_url',
                'image_url': {
                  'url': 'data:$mimeType;base64,$imageBase64',
                },
              },
              {
                'type': 'text',
                'text': prompt,
              },
            ],
          },
        ],
      };

      AppLogger.apiRequestRaw('POST', '/chat/completions (è±†åŒ…å›¾ç‰‡åˆ†æ)', requestData);
      AppLogger.info('è±†åŒ…-ARK', 'å¼€å§‹åˆ†æå›¾ç‰‡ç‰¹å¾...');

      final response = await _doubaoDio.post(
        '/chat/completions',
        data: requestData,
      );

      AppLogger.apiResponseRaw('/chat/completions (è±†åŒ…å›¾ç‰‡åˆ†æ)', response.data);

      // è§£æè±†åŒ…å“åº”ï¼ˆOpenAI æ ¼å¼ï¼‰
      final choices = response.data['choices'] as List?;
      if (choices == null || choices.isEmpty) {
        AppLogger.error('è±†åŒ…-ARK', 'å“åº”æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ choices', null, StackTrace.current);
        throw Exception('å›¾ç‰‡åˆ†æå¤±è´¥ï¼šå“åº”æ ¼å¼é”™è¯¯');
      }

      final firstChoice = choices[0] as Map<String, dynamic>?;
      final message = firstChoice?['message'] as Map<String, dynamic>?;
      final content = message?['content'] as String?;

      if (content == null || content.isEmpty) {
        AppLogger.error('è±†åŒ…-ARK', 'å›¾ç‰‡åˆ†æå“åº”ä¸ºç©º', null, StackTrace.current);
        throw Exception('å›¾ç‰‡åˆ†æå¤±è´¥ï¼šå“åº”ä¸ºç©º');
      }

      AppLogger.success('è±†åŒ…-ARK', 'å›¾ç‰‡åˆ†æå®Œæˆ');
      AppLogger.info('è±†åŒ…-ARK', 'æå–çš„ç‰¹å¾:\n$content');
      return content;
    } catch (e) {
      AppLogger.error('è±†åŒ…-ARK', 'å›¾ç‰‡åˆ†æå¤±è´¥', e, StackTrace.current);
      throw Exception('å›¾ç‰‡åˆ†æå¤±è´¥: $e');
    }
  }

  // ==================== æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡ API (Gemini) ====================

  /// ä½¿ç”¨å›¾ç‰‡ç”Ÿæˆ API ç”Ÿæˆå›¾ç‰‡
  /// æ”¯æŒæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾ï¼ˆä¼ å…¥å‚è€ƒå›¾ï¼‰
  /// [prompt] å›¾åƒæè¿°æ–‡æœ¬
  /// [referenceImages] å‚è€ƒå›¾ç‰‡åˆ—è¡¨ï¼ˆbase64 æ ¼å¼ï¼Œæ”¯æŒå¤šå›¾ï¼‰ï¼Œç”¨äºå›¾ç”Ÿå›¾
  /// è¿”å›ç”Ÿæˆçš„å›¾ç‰‡ URL
  Future<String> generateImage(
    String prompt, {
    List<String>? referenceImages,
  }) async {
    // ========================================
    // Mock æ¨¡å¼ï¼šç›´æ¥è¿”å›æ¨¡æ‹Ÿç»“æœ
    // ========================================
    if (ApiConfig.USE_MOCK_IMAGE_API) {
      AppLogger.warn('å›¾ç‰‡ç”Ÿæˆ', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼ï¼Œä¸è°ƒç”¨çœŸå® API');
      AppLogger.info('å›¾ç‰‡ç”Ÿæˆ[MOCK]', 'Prompt: $prompt');
      if (referenceImages != null && referenceImages.isNotEmpty) {
        AppLogger.info('å›¾ç‰‡ç”Ÿæˆ[MOCK]', 'å‚è€ƒå›¾æ•°é‡: ${referenceImages.length}');
      }
      // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
      await Future.delayed(const Duration(milliseconds: 500));
      AppLogger.success('å›¾ç‰‡ç”Ÿæˆ[MOCK]', 'è¿”å› Mock å›¾ç‰‡: ${ApiConfig.MOCK_IMAGE_URL}');
      return ApiConfig.MOCK_IMAGE_URL;
    }

    // ========================================
    // çœŸå® API è°ƒç”¨æ¨¡å¼
    // ========================================
    return _generateImageWithRetry(prompt, referenceImages: referenceImages);
  }

  /// å¸¦é‡è¯•æœºåˆ¶çš„å›¾ç‰‡ç”Ÿæˆï¼ˆå¤„ç†å†…å®¹å®‰å…¨æ£€æŸ¥é”™è¯¯ï¼‰
  Future<String> _generateImageWithRetry(
    String prompt, {
    List<String>? referenceImages,
    int retryCount = 0,
  }) async {
    try {
      final requestData = {
        'model': 'gemini-2.5-flash-image-vip',
        // 'model': 'gemini-3-pro-image-preview',
        'prompt': prompt,
        'n': 1,
        'response_format': 'url',
        'size': '1024x1024',
      };

      // å¦‚æœæœ‰å‚è€ƒå›¾ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­ï¼ˆå›¾ç”Ÿå›¾ï¼‰
      if (referenceImages != null && referenceImages.isNotEmpty) {
        // API æ”¯æŒæ•°ç»„æ ¼å¼ï¼š["base64xxx", "base64yyy"]
        // æˆ– URL æ ¼å¼ï¼š["https://xxx", "https://yyy"]
        requestData['image'] = referenceImages;
        AppLogger.info('å›¾ç‰‡ç”Ÿæˆ', 'å›¾ç”Ÿå›¾æ¨¡å¼ï¼Œå‚è€ƒå›¾æ•°é‡: ${referenceImages.length}');
      }

      AppLogger.apiRequestRaw('POST', '/v1/images/generations', requestData);
      AppLogger.info('å›¾ç‰‡ç”Ÿæˆ', 'å¼€å§‹ç”Ÿæˆå›¾ç‰‡: $prompt');

      final response = await _imageDio.post(
        '/v1/images/generations',
        data: requestData,
        options: Options(sendTimeout: const Duration(seconds: 500), receiveTimeout: const Duration(seconds: 500)),
      );

      AppLogger.apiResponseRaw('/v1/images/generations', response.data);

      // ä»å“åº”ä¸­è§£æå›¾ç‰‡ URL: response.data['data'][0]['url']
      final dataList = response.data['data'] as List?;
      if (dataList == null || dataList.isEmpty) {
        AppLogger.error('å›¾ç‰‡ç”Ÿæˆ', 'å“åº”ä¸­æ²¡æœ‰ data æ•°ç»„', null, StackTrace.current);
        throw Exception('å›¾ç‰‡ç”Ÿæˆå“åº”ä¸­æ²¡æœ‰ data æ•°ç»„');
      }

      final firstImage = dataList[0] as Map<String, dynamic>?;
      if (firstImage == null) {
        AppLogger.error('å›¾ç‰‡ç”Ÿæˆ', 'data[0] ä¸ºç©º', null, StackTrace.current);
        throw Exception('å›¾ç‰‡ç”Ÿæˆå“åº” data[0] ä¸ºç©º');
      }

      final imageUrl = firstImage['url'] as String?;
      if (imageUrl == null || imageUrl.isEmpty) {
        AppLogger.error('å›¾ç‰‡ç”Ÿæˆ', 'å›¾ç‰‡ URL ä¸ºç©º', null, StackTrace.current);
        throw Exception('å›¾ç‰‡ç”Ÿæˆå“åº”ä¸­ URL ä¸ºç©º');
      }

      AppLogger.success('å›¾ç‰‡ç”Ÿæˆ', 'æˆåŠŸç”Ÿæˆå›¾ç‰‡: $imageUrl');
      return imageUrl;
    } catch (e) {
      AppLogger.error('å›¾ç‰‡ç”Ÿæˆ', 'ç”Ÿæˆå›¾ç‰‡å¤±è´¥', e, StackTrace.current);

      // æ£€æŸ¥æ˜¯å¦æ˜¯å†…å®¹å®‰å…¨æ£€æŸ¥é”™è¯¯
      if (e is DioException) {
        final errorData = e.response?.data;
        if (errorData is Map) {
          final message = errorData['message']?.toString() ?? '';
          if (message.contains('PUBLIC_ERROR_UNSAFE_GENERATION') ||
              message.contains('generation_failed')) {
            // å¦‚æœè¿˜æ²¡é‡è¯•è¿‡ï¼Œåˆ™æ¸…ç†æç¤ºè¯åé‡è¯•
            if (retryCount == 0) {
              AppLogger.warn('å›¾ç‰‡ç”Ÿæˆ', 'è§¦å‘å†…å®¹å®‰å…¨æ£€æŸ¥ï¼Œæ­£åœ¨è°ƒæ•´æç¤ºè¯å¹¶é‡è¯•...');
              final sanitizedPrompt = _sanitizePrompt(prompt);
              return _generateImageWithRetry(
                sanitizedPrompt,
                referenceImages: referenceImages,
                retryCount: retryCount + 1,
              );
            } else {
              AppLogger.error('å›¾ç‰‡ç”Ÿæˆ', 'è°ƒæ•´åä»æ— æ³•é€šè¿‡å®‰å…¨æ£€æŸ¥ï¼Œæ”¾å¼ƒé‡è¯•', null, StackTrace.current);
            }
          }
        }
      }

      throw Exception('å›¾ç‰‡ç”Ÿæˆé”™è¯¯: $e');
    }
  }

  /// æ¸…ç†æç¤ºè¯ï¼Œç§»é™¤å¯èƒ½è§¦å‘å†…å®¹å®‰å…¨æ£€æŸ¥çš„å†…å®¹
  String _sanitizePrompt(String prompt) {
    // ç§»é™¤æˆ–æ›¿æ¢å¯èƒ½å¯¼è‡´å®‰å…¨æ£€æŸ¥å¤±è´¥çš„æ•æ„Ÿè¯æ±‡
    final sanitized = prompt
        // ç§»é™¤è¿‡äºæš´éœ²çš„æè¿°
        .replaceAll(RegExp(r'\b(sexy|nude|naked|breast|underwear|lingerie|intimate|suggestive)\b', caseSensitive: false), 'beautiful')
        // ç§»é™¤æš´åŠ›ç›¸å…³è¯æ±‡
        .replaceAll(RegExp(r'\b(violence|blood|kill|death|weapon|gore)\b', caseSensitive: false), 'dramatic')
        // ç§»é™¤å…¶ä»–å¯èƒ½çš„æ•æ„Ÿè¯
        .replaceAll(RegExp(r'\b(disturbing|shocking|offensive)\b', caseSensitive: false), 'artistic')
        // ç®€åŒ–è¿‡äºå¤æ‚çš„æè¿°
        .replaceAll(RegExp(r'\b(highly detailed|extreme|intense|realistic skin|anatomically correct)\b', caseSensitive: false), 'detailed')
        // ä¿ç•™æ ¸å¿ƒå†…å®¹ï¼Œæ·»åŠ å®‰å…¨çš„è‰ºæœ¯æè¿°
        .trim();

    final result = sanitized.isEmpty
        ? 'Beautiful artistic scene, professional photography, high quality, cinematic lighting'
        : '$sanitized, professional photography, high quality, cinematic lighting';

    AppLogger.info('æç¤ºè¯æ¸…ç†', 'åŸæç¤ºè¯: $prompt');
    AppLogger.info('æç¤ºè¯æ¸…ç†', 'æ¸…ç†å: $result');

    return result;
  }

  /// æ¸…ç†è§†é¢‘æç¤ºè¯ï¼Œç§»é™¤å¯èƒ½è§¦å‘ reCAPTCHA/å†…å®¹å®‰å…¨æ£€æŸ¥çš„æ•æ„Ÿå…ƒç´ 
  /// è§†é¢‘ç”Ÿæˆå¯¹æç¤ºè¯æ›´æ•æ„Ÿï¼Œéœ€è¦æ›´ç§¯æçš„å¤„ç†
  String _sanitizeVideoPrompt(String prompt) {
    AppLogger.info('è§†é¢‘æç¤ºè¯æ¸…ç†', 'åŸå§‹æç¤ºè¯: $prompt');

    // ç§»é™¤æˆ–æ›¿æ¢å¯èƒ½å¯¼è‡´è§†é¢‘ç”Ÿæˆå¤±è´¥çš„æ•æ„Ÿè¯æ±‡
    String sanitized = prompt;

    // ç§»é™¤æš´åŠ›/å±é™©ç›¸å…³å…ƒç´ ï¼ˆè¿™äº›ä¼šè§¦å‘ reCAPTCHAï¼‰
    final violentPatterns = [
      r'lightning\s+effects?', // é—ªç”µæ•ˆæœ
      r'glowing\s+(eyes|hands|body)', // å‘å…‰çš„çœ¼ç›/æ‰‹/èº«ä½“
      r'electric\s+\w+', // ç”µæµç›¸å…³
      r'energy\s+swirl', // èƒ½é‡æ—‹æ¶¡
      r'powerful?\s+\w+', // å¼ºåŠ›/å¼ºå¤§çš„
      r'explosion', // çˆ†ç‚¸
      r'fire\s+\w+', // ç«ç„°
      r'violent?\s+\w+', // æš´åŠ›
      r'attack\s+\w+', // æ”»å‡»
      r'battle\s+\w+', // æˆ˜æ–—
      r'fight\s+\w+', // æ‰“æ–—
      r'weapon', // æ­¦å™¨
      r'danger', // å±é™©
      r'threaten', // å¨èƒ
      r'aggressive', // æ¿€è¿›
      r'intense', // å¼ºçƒˆï¼ˆå¯èƒ½è¢«è¯¯åˆ¤ï¼‰
      r'dramatic\s+lightning', // æˆå‰§æ€§é—ªç”µ
      r'fierce', // å‡¶çŒ›
      r'determination\s*\([^)]*\)', // åšå®šçš„ï¼ˆå¯èƒ½å¸¦çœ¼ç›æè¿°ï¼‰
      r'sweating', // æµæ±—ï¼ˆç´§å¼ æ°›å›´ï¼‰
      r'trembling\s+spoon', // é¢¤æŠ–çš„å‹ºå­
      r'gripping\s+spoon', // ç´§æ¡å‹ºå­
    ];

    for (final pattern in violentPatterns) {
      sanitized = sanitized.replaceAll(RegExp(pattern, caseSensitive: false), 'gentle');
    }

    // æ›¿æ¢ä¸ºç§¯ææ­£å‘çš„è¯æ±‡
    final replacements = {
      'lightning': 'soft light',
      'glowing': 'bright',
      'energy': 'atmosphere',
      'swirl': 'flow',
      'powerful': 'beautiful',
      'strong': 'elegant',
      'fierce': 'calm',
      'intense': 'warm',
      'dramatic': 'peaceful',
      'action': 'scene',
      'dynamic': 'smooth',
      'gripping': 'holding',
      'trembling': 'gentle',
    };

    for (final entry in replacements.entries) {
      sanitized = sanitized.replaceAll(RegExp(entry.key, caseSensitive: false), entry.value);
    }

    // æ·»åŠ å®‰å…¨çš„å‰ç¼€å’Œåç¼€
    final result = 'Peaceful anime style scene. $sanitized. Calm and positive atmosphere.';

    AppLogger.info('è§†é¢‘æç¤ºè¯æ¸…ç†', 'æ¸…ç†åæç¤ºè¯: $result');

    return result;
  }

  /// ä½¿ç”¨ AI é‡å†™è§†é¢‘æç¤ºè¯ï¼Œä¿ç•™åŸæ„ä½†ä½¿ç”¨å®‰å…¨çš„è¡¨è¾¾æ–¹å¼
  /// ç”¨äºé‡è¯•å¤±è´¥çš„è§†é¢‘ç”Ÿæˆä»»åŠ¡
  Future<String> rewriteVideoPromptForSafety({
    required String originalPrompt,
    required String sceneNarration, // åœºæ™¯æ—ç™½ï¼Œå¸®åŠ©ç†è§£ä¸Šä¸‹æ–‡
  }) async {
    AppLogger.info('æç¤ºè¯é‡å†™', 'åŸå§‹æç¤ºè¯: $originalPrompt');
    AppLogger.info('æç¤ºè¯é‡å†™', 'åœºæ™¯æ—ç™½: $sceneNarration');

    final rewritePrompt = '''
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘æç¤ºè¯ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†è§†é¢‘æç¤ºè¯é‡å†™ä¸º100%å®‰å…¨çš„è¡¨è¾¾æ–¹å¼ï¼Œç¡®ä¿é€šè¿‡å¹³å°çš„å†…å®¹å®¡æ ¸ã€‚

**åŸå§‹åœºæ™¯æ—ç™½**:
$sceneNarration

**åŸå§‹è§†é¢‘æç¤ºè¯**:
$originalPrompt

*** å…³é”®ï¼šå¿…é¡»ä¸¥æ ¼é¿å…ä»¥ä¸‹æ‰€æœ‰ç¦ç”¨è¯æ±‡ ***

ç»å¯¹ç¦æ­¢çš„è¯æ±‡ï¼ˆä¼šå¯¼è‡´å¹³å°æ‹’ç»ï¼‰:
- èƒ½é‡/ç‰¹æ•ˆç±»: lightning, electric, thunderbolt, energy, power surge, spark, voltage, current
- æˆ˜æ–—/å†²çªç±»: attack, battle, fight, punch, kick, hit, strike, slam, crash, smash, beat, combat, clash, struggle
- å±é™©å…ƒç´ : fire, flame, burn, explosion, explode, blast, bomb, smoke, weapon, sword, knife, gun
- è´Ÿé¢æƒ…ç»ª: fierce, intense, aggressive, violent, rage, angry, furious, terrified, scream, shout, yell, panic
- èº«ä½“ææ€–: glowing eyes, red eyes, blood, wound, injury, transform, mutate, distort, twisted
- å±é™©åŠ¨ä½œ: fall, drop, trip, stumble, chase, flee, escape, running

å®‰å…¨æ›¿ä»£è¯æ±‡ï¼ˆå¿…é¡»ä½¿ç”¨ï¼‰:
- lightning/electric â†’ soft light, warm light, gentle light, ambient light
- fight/attack â†’ move toward, approach, face each other, interaction
- fierce/intense â†’ warm, calm, gentle, peaceful, soft
- explosion/fire â†’ bloom, brighten, illuminate, radiate
- angry/rage â†’ concerned, surprised, amazed, excited

æ¯ä¸ªæç¤ºè¯å¿…é¡»åŒ…å«è‡³å°‘2ä¸ªå®‰å…¨è¯æ±‡:
gentle, soft, calm, peaceful, warm, bright, smooth, quiet, serene, beautiful, lovely, sweet, slowly, smoothly, gracefully

é•œå¤´ç§»åŠ¨å¿…é¡»ä½¿ç”¨: slowly, gently, softly, calmly
ç»ä¸èƒ½ä½¿ç”¨: quick, fast, sudden, rapid, sharp, violent

è¯·ç›´æ¥è¾“å‡ºé‡å†™åçš„è‹±æ–‡æç¤ºè¯ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€‚ç¡®ä¿æç¤ºè¯50è¯ä»¥å†…ï¼ŒåŒ…å«åœºæ™¯çš„æ ¸å¿ƒåŠ¨ä½œå’Œæƒ…æ„Ÿã€‚
''';

    try {
      final response = await _dio.post(
        '/chat/completions',
        data: {
          'model': 'glm-4-flash', // ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
          'messages': [
            {'role': 'user', 'content': rewritePrompt}
          ],
          'temperature': 0.7,
        },
      );

      AppLogger.apiResponseRaw('/chat/completions (æç¤ºè¯é‡å†™)', response.data);

      // è§£æ GLM å“åº”ï¼ˆOpenAI æ ¼å¼ï¼‰
      final choices = response.data['choices'] as List?;
      if (choices == null || choices.isEmpty) {
        throw Exception('GLM API å“åº”æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ choices');
      }

      final firstChoice = choices[0] as Map<String, dynamic>?;
      final message = firstChoice?['message'] as Map<String, dynamic>?;
      final rewrittenPrompt = message?['content'] as String?;

      if (rewrittenPrompt == null || rewrittenPrompt.isEmpty) {
        throw Exception('GLM API å“åº”ä¸­æ²¡æœ‰å†…å®¹');
      }

      final cleaned = rewrittenPrompt.trim();

      AppLogger.success('æç¤ºè¯é‡å†™', 'é‡å†™åæç¤ºè¯: $cleaned');
      return cleaned;
    } catch (e) {
      AppLogger.error('æç¤ºè¯é‡å†™', 'AIé‡å†™å¤±è´¥ï¼Œä½¿ç”¨ç®€å•è¿‡æ»¤', e);
      // é™çº§åˆ°ç®€å•è¿‡æ»¤
      return _sanitizeVideoPrompt(originalPrompt);
    }
  }

  // ==================== Chat æ ¼å¼å›¾ç”Ÿå›¾ API (è§’è‰²ä¸€è‡´æ€§) ====================

  /// ä½¿ç”¨ chat æ ¼å¼å›¾ç”Ÿå›¾ API ç”Ÿæˆå›¾ç‰‡ï¼ˆæ”¯æŒä¼ å…¥è§’è‰²å‚è€ƒå›¾ URLï¼‰
  /// ç”¨äºåœºæ™¯2+çš„å›¾ç‰‡ç”Ÿæˆï¼Œé€šè¿‡ä¼ å…¥è§’è‰²ä¸‰è§†å›¾ä¿æŒäººç‰©ä¸€è‡´æ€§
  /// [prompt] åœºæ™¯æè¿°æ–‡æœ¬
  /// [characterImageUrls] è§’è‰²å‚è€ƒå›¾ URL åˆ—è¡¨ï¼ˆä¸‰è§†å›¾ï¼‰
  /// è¿”å›ç”Ÿæˆçš„å›¾ç‰‡ URL
  Future<String> generateImageWithCharacterReference(
    String prompt, {
    required List<String> characterImageUrls,
  }) async {
    // Mock æ¨¡å¼
    if (ApiConfig.USE_MOCK_IMAGE_API) {
      AppLogger.warn('å›¾ç”Ÿå›¾(è§’è‰²)', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼');
      AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)[MOCK]', 'Prompt: $prompt');
      AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)[MOCK]', 'å‚è€ƒå›¾æ•°é‡: ${characterImageUrls.length}');
      await Future.delayed(const Duration(milliseconds: 500));
      return ApiConfig.MOCK_IMAGE_URL;
    }

    AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'å¼€å§‹ç”Ÿæˆï¼Œå‚è€ƒå›¾æ•°é‡: ${characterImageUrls.length}');
    AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'Prompt: $prompt');

    try {
      final dio = Dio(BaseOptions(
        baseUrl: ApiConfig.tuziBaseUrl,
        connectTimeout: const Duration(seconds: 60),
        receiveTimeout: const Duration(seconds: 500),
        headers: {
          'Authorization': 'Bearer ${ApiConfig.imageApiKey}',
          'Content-Type': 'application/json',
        },
      ));

      // æ„å»º content æ•°ç»„ï¼šæ–‡æœ¬ + å¤šå¼ å‚è€ƒå›¾
      final List<Map<String, dynamic>> contentItems = [];

      // æ·»åŠ æ–‡æœ¬æç¤º
      contentItems.add({
        'type': 'text',
        'text': prompt,
      });

      // æ·»åŠ è§’è‰²å‚è€ƒå›¾ï¼ˆä¸‰è§†å›¾ï¼‰
      for (final imageUrl in characterImageUrls) {
        if (imageUrl.isNotEmpty) {
          contentItems.add({
            'type': 'image_url',
            'image_url': {
              'url': imageUrl,
            },
          });
        }
      }

      final requestBody = {
        'model': 'gpt-4o-image-vip',
        'stream': false,
        'messages': [
          {
            'role': 'user',
            'content': contentItems,
          }
        ],
      };

      AppLogger.apiRequestRaw('POST', '/v1/chat/completions (å›¾ç”Ÿå›¾)', requestBody);
      AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'å‘é€è¯·æ±‚...');
      final response = await dio.post(
        '/v1/chat/completions',
        data: requestBody,
      );

      AppLogger.apiResponseRaw('/v1/chat/completions (å›¾ç”Ÿå›¾)', response.data);

      if (response.statusCode == 200) {
        final data = response.data;

        // è§£æå“åº”è·å–å›¾ç‰‡ URL
        // å“åº”æ ¼å¼: { choices: [{ message: { content: "url" } }] }
        final choices = data['choices'] as List?;
        if (choices != null && choices.isNotEmpty) {
          final message = choices[0]['message'];
          final content = message['content'];

          // content å¯èƒ½æ˜¯å­—ç¬¦ä¸² URL æˆ–åŒ…å«å›¾ç‰‡çš„ç»“æ„
          String? imageUrl;
          if (content is String) {
            // ç›´æ¥æ˜¯ URL å­—ç¬¦ä¸²
            if (content.startsWith('http')) {
              imageUrl = content;
            } else {
              // å¯èƒ½æ˜¯ Markdown æ ¼å¼çš„å¤æ‚å“åº”ï¼Œéœ€è¦æå–å›¾ç‰‡ URL
              try {
                final parsed = content;

                // ç­–ç•¥1: ä¼˜å…ˆåŒ¹é… markdown å›¾ç‰‡æ ¼å¼ ![alt](url)
                final markdownImageMatch = RegExp(r'!\[.*?\]\((https://pro\.filesystem\.site/cdn/[^\)]+)\)').firstMatch(parsed);
                if (markdownImageMatch != null) {
                  imageUrl = markdownImageMatch.group(1);
                  AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'ä» Markdown å›¾ç‰‡æ ¼å¼æå– URL: $imageUrl');
                }

                // ç­–ç•¥2: å¦‚æœæ²¡æ‰¾åˆ°ï¼ŒåŒ¹é… pro.filesystem.site çš„å›¾ç‰‡ URL
                if (imageUrl == null) {
                  final cdnUrlMatch = RegExp(r'https://pro\.filesystem\.site/cdn/[^\s\])"]+').firstMatch(parsed);
                  if (cdnUrlMatch != null) {
                    imageUrl = cdnUrlMatch.group(0);
                    AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'ä» CDN URL æå–: $imageUrl');
                  }
                }

                // ç­–ç•¥3: å…œåº• - æå–æ‰€æœ‰ URL å¹¶è¿‡æ»¤é¢„è§ˆé¡µé¢
                if (imageUrl == null) {
                  final allUrls = RegExp(r'https?://[^\s\])"]+').allMatches(parsed).map((m) => m.group(0)!).toList();
                  AppLogger.info('å›¾ç”Ÿå›¾(è§’è‰²)', 'æ‰¾åˆ°çš„æ‰€æœ‰ URL: $allUrls');
                  // è¿‡æ»¤æ‰ pro.asyncdata.net/web é¢„è§ˆé“¾æ¥
                  for (final url in allUrls) {
                    if (!url.contains('pro.asyncdata.net/web')) {
                      imageUrl = url;
                      break;
                    }
                  }
                }
              } catch (e) {
                AppLogger.error('å›¾ç”Ÿå›¾(è§’è‰²)', 'è§£æ URL å¤±è´¥: $e', e, StackTrace.current);
              }
            }
          } else if (content is List) {
            // content æ˜¯æ•°ç»„ï¼ŒæŸ¥æ‰¾å›¾ç‰‡ç±»å‹
            for (final item in content) {
              if (item['type'] == 'image_url') {
                imageUrl = item['image_url']?['url'];
                break;
              }
            }
          }

          if (imageUrl != null && imageUrl.isNotEmpty) {
            AppLogger.success('å›¾ç”Ÿå›¾(è§’è‰²)', 'å›¾ç‰‡ç”ŸæˆæˆåŠŸ: $imageUrl');
            return imageUrl;
          }
        }

        AppLogger.error('å›¾ç”Ÿå›¾(è§’è‰²)', 'å“åº”ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ URL', null, StackTrace.current);
        throw Exception('å“åº”ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ URL');
      } else {
        throw Exception('è¯·æ±‚å¤±è´¥: ${response.statusCode}');
      }
    } catch (e) {
      AppLogger.error('å›¾ç”Ÿå›¾(è§’è‰²)', 'ç”Ÿæˆå¤±è´¥: $e', e, StackTrace.current);

      // å¦‚æœæ–°æ¥å£å¤±è´¥ï¼Œé™çº§ä½¿ç”¨åŸæœ‰çš„æ–‡æœ¬ç”Ÿæˆæ–¹å¼
      AppLogger.warn('å›¾ç”Ÿå›¾(è§’è‰²)', 'é™çº§åˆ°æ–‡æœ¬ç”Ÿæˆæ¨¡å¼');
      return generateImage(prompt);
    }
  }

  // ==================== è§’è‰²ä¸‰è§†å›¾ç”Ÿæˆ API ====================

  /// ä¸ºè§’è‰²ç”Ÿæˆç»„åˆä¸‰è§†å›¾ï¼ˆä¸€å¼ å›¾åŒ…å«æ­£é¢ã€ä¾§é¢ã€èƒŒé¢ä¸‰ä¸ªè§†è§’ï¼‰
  /// æ–°ç‰ˆæœ¬ï¼šç”Ÿæˆå•å¼ ç»„åˆå›¾ï¼Œç”¨äºè§†é¢‘ç”Ÿæˆæ—¶ä¿æŒäººç‰©ä¸€è‡´æ€§
  /// [characterName] è§’è‰²åç§°
  /// [description] è§’è‰²æè¿°
  /// [referenceImages] å‚è€ƒå›¾ç‰‡ï¼ˆç”¨æˆ·ä¸Šä¼ çš„è§’è‰²å‚è€ƒå›¾ï¼‰
  /// [onProgress] è¿›åº¦å›è°ƒ (0.0 - 1.0)
  /// è¿”å› CharacterSheet å¯¹è±¡ï¼ŒåŒ…å«ç»„åˆä¸‰è§†å›¾ URL
  Future<CharacterSheet> generateCharacterSheets(
    String characterName,
    String description, {
    List<String>? referenceImages,
    void Function(double progress, String status)? onProgress,
  }) async {
    AppLogger.info('è§’è‰²ä¸‰è§†å›¾', 'å¼€å§‹ç”Ÿæˆè§’è‰² $characterName çš„ç»„åˆä¸‰è§†å›¾');

    // ========================================
    // Mock æ¨¡å¼ï¼šç›´æ¥è¿”å›æ¨¡æ‹Ÿç»“æœ
    // ========================================
    if (ApiConfig.USE_MOCK_CHARACTER_SHEET_API) {
      AppLogger.warn('è§’è‰²ä¸‰è§†å›¾', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼ï¼Œä¸è°ƒç”¨çœŸå® API');
      AppLogger.info('è§’è‰²ä¸‰è§†å›¾[MOCK]', 'è§’è‰²å: $characterName');
      AppLogger.info('è§’è‰²ä¸‰è§†å›¾[MOCK]', 'æè¿°: $description');
      if (referenceImages != null && referenceImages.isNotEmpty) {
        AppLogger.info('è§’è‰²ä¸‰è§†å›¾[MOCK]', 'å‚è€ƒå›¾æ•°é‡: ${referenceImages.length}');
      }

      onProgress?.call(0.0, 'å‡†å¤‡ç”Ÿæˆè§’è‰²ç»„åˆä¸‰è§†å›¾...');

      // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
      await Future.delayed(const Duration(milliseconds: 500));

      onProgress?.call(0.5, 'ç”Ÿæˆç»„åˆä¸‰è§†å›¾...');
      await Future.delayed(const Duration(milliseconds: 500));
      AppLogger.success('è§’è‰²ä¸‰è§†å›¾[MOCK]', 'ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆ: ${ApiConfig.MOCK_CHARACTER_COMBINED_URL}');

      final sheetId = 'char_${DateTime.now().millisecondsSinceEpoch}';
      final characterId = 'char_${characterName.hashCode}';

      final completedSheet = CharacterSheet(
        id: sheetId,
        characterId: characterId,
        characterName: characterName,
        description: description,
        role: 'ä¸»è§’',
        combinedViewUrl: ApiConfig.MOCK_CHARACTER_COMBINED_URL,
        status: CharacterSheetStatus.completed,
      );

      onProgress?.call(1.0, 'è§’è‰²ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆï¼');
      AppLogger.success('è§’è‰²ä¸‰è§†å›¾[MOCK]', 'è§’è‰² $characterName çš„ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆ');

      return completedSheet;
    }

    // ========================================
    // çœŸå® API è°ƒç”¨æ¨¡å¼
    // ========================================

    // åˆ›å»ºè§’è‰²è®¾å®šè¡¨å¯¹è±¡
    final sheetId = 'char_${DateTime.now().millisecondsSinceEpoch}';
    final characterId = 'char_${characterName.hashCode}';

    onProgress?.call(0.0, 'å‡†å¤‡ç”Ÿæˆè§’è‰²ç»„åˆä¸‰è§†å›¾...');

    try {
      // ç”Ÿæˆç»„åˆä¸‰è§†å›¾ï¼ˆä¸€å¼ å›¾åŒ…å«æ­£é¢ã€ä¾§é¢ã€èƒŒé¢ï¼‰
      onProgress?.call(0.2, 'ç”Ÿæˆç»„åˆä¸‰è§†å›¾...');
      final combinedPrompt = _buildCombinedViewPrompt(description);
      final combinedUrl = await generateImage(
        combinedPrompt,
        referenceImages: referenceImages,
      );
      AppLogger.success('è§’è‰²ä¸‰è§†å›¾', 'ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆ: $combinedUrl');

      // åˆ›å»ºå®Œæˆçš„è§’è‰²è®¾å®šè¡¨
      final completedSheet = CharacterSheet(
        id: sheetId,
        characterId: characterId,
        characterName: characterName,
        description: description,
        role: 'ä¸»è§’',
        combinedViewUrl: combinedUrl,
        status: CharacterSheetStatus.completed,
      );

      onProgress?.call(1.0, 'è§’è‰²ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆï¼');
      AppLogger.success('è§’è‰²ä¸‰è§†å›¾', 'è§’è‰² $characterName çš„ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå®Œæˆ');

      return completedSheet;
    } catch (e) {
      AppLogger.error('è§’è‰²ä¸‰è§†å›¾', 'ç”Ÿæˆè§’è‰²ç»„åˆä¸‰è§†å›¾å¤±è´¥', e, StackTrace.current);
      throw Exception('è§’è‰²ç»„åˆä¸‰è§†å›¾ç”Ÿæˆå¤±è´¥: $e');
    }
  }

  /// æ„å»ºç»„åˆä¸‰è§†å›¾çš„æç¤ºè¯
  /// ç”Ÿæˆä¸€å¼ å›¾ç‰‡ï¼ŒåŒ…å«è§’è‰²çš„æ­£é¢ã€ä¾§é¢ã€èƒŒé¢ä¸‰ä¸ªè§†è§’
  String _buildCombinedViewPrompt(String description) {
    // åŸºç¡€æè¿°
    final baseDesc = description.isNotEmpty
        ? description
        : 'A character in anime/manga style';

    // ç»„åˆä¸‰è§†å›¾æç¤ºè¯
    return '''
Character turnaround sheet with three views side by side:
LEFT: Front view (facing forward)
CENTER: Side view (profile, facing right)
RIGHT: Back view (showing the back)

Character: $baseDesc

Layout: Three full body shots arranged horizontally in a single image
Style: anime/manga art style, clean line art, flat colors, professional character design sheet, character reference sheet
Quality: high quality, detailed, 4k, consistent proportions across all views
Background: plain white or light gray background
Composition: all three views same size, equal spacing, full body visible, neutral standing pose, T-pose or A-pose preferred
'''.trim();
  }

  /// å…¼å®¹æ—§ç‰ˆï¼šæ„å»ºå•è§†å›¾æç¤ºè¯
  @Deprecated('ä½¿ç”¨ _buildCombinedViewPrompt æ›¿ä»£')
  String _buildCharacterViewPrompt(String description, CharacterViewType viewType) {
    // åŸºç¡€æè¿°
    final baseDesc = description.isNotEmpty
        ? description
        : 'A character in anime/manga style';

    // æ ¹æ®è§†å›¾ç±»å‹æ·»åŠ ç‰¹å®šæè¿°
    final viewDesc = viewType == CharacterViewType.front
        ? 'front view, facing forward, full body shot, standing pose'
        : viewType == CharacterViewType.back
            ? 'back view, showing the back of the character, full body shot, standing pose'
            : 'side view, profile view, full body shot, standing pose';

    // ç»„åˆæç¤ºè¯
    return '''
$viewDesc

Character: $baseDesc

Style: anime/manga art style, clean line art, flat colors, professional character design sheet
Quality: high quality, detailed, 4k
Background: plain white or light gray background for character reference
Composition: centered, full body visible, neutral standing pose
'''.trim();
  }

  /// æ‰¹é‡ç”Ÿæˆå¤šä¸ªè§’è‰²çš„ä¸‰è§†å›¾
  /// [characters] è§’è‰²åˆ—è¡¨ï¼Œæ ¼å¼ä¸º {'name': 'è§’è‰²å', 'description': 'æè¿°'}
  /// [referenceImages] å‚è€ƒå›¾ç‰‡
  /// [onProgress] è¿›åº¦å›è°ƒ (overall 0.0 - 1.0)
  /// è¿”å›è§’è‰²è®¾å®šè¡¨åˆ—è¡¨
  Future<List<CharacterSheet>> generateMultipleCharacterSheets(
    List<Map<String, String>> characters, {
    List<String>? referenceImages,
    void Function(double progress, String status)? onProgress,
  }) async {
    final List<CharacterSheet> sheets = [];

    for (int i = 0; i < characters.length; i++) {
      final char = characters[i];
      final name = char['name'] ?? 'è§’è‰²${i + 1}';
      final desc = char['description'] ?? '';

      final overallProgress = i / characters.length;
      onProgress?.call(
        overallProgress,
        'æ­£åœ¨ç”Ÿæˆ $name çš„ä¸‰è§†å›¾ (${i + 1}/${characters.length})...',
      );

      final sheet = await generateCharacterSheets(
        name,
        desc,
        referenceImages: referenceImages,
        onProgress: (viewProgress, viewStatus) {
          // å°†å•è§’è‰²è¿›åº¦è½¬æ¢ä¸ºæ€»è¿›åº¦
          final currentOverall = (i + viewProgress) / characters.length;
          onProgress?.call(currentOverall, viewStatus);
        },
      );

      sheets.add(sheet);
    }

    onProgress?.call(1.0, 'æ‰€æœ‰è§’è‰²ä¸‰è§†å›¾ç”Ÿæˆå®Œæˆï¼');
    return sheets;
  }

  // ==================== å›¾ç‰‡ç”Ÿæˆè§†é¢‘ API (Tuzi Sora) ====================

  /// ä» URL ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
  Future<File> _downloadImage(String imageUrl) async {
    try {
      // ä¸‹è½½å›¾ç‰‡
      final response = await _dio.get(
        imageUrl,
        options: Options(responseType: ResponseType.bytes),
      );

      // è·å–ä¸´æ—¶ç›®å½•
      final tempDir = await getTemporaryDirectory();

      // ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final extension = path.extension(imageUrl).isNotEmpty
          ? path.extension(imageUrl)
          : '.png';
      final filename = 'temp_image_$timestamp$extension';
      final filePath = path.join(tempDir.path, filename);

      // å†™å…¥æ–‡ä»¶
      final file = File(filePath);
      await file.writeAsBytes(response.data as List<int>);

      return file;
    } catch (e) {
      throw Exception('å›¾ç‰‡ä¸‹è½½é”™è¯¯: $e');
    }
  }

  /// ä½¿ç”¨ Tuzi è§†é¢‘ç”Ÿæˆ API ä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘ï¼ˆå¼‚æ­¥ä»»åŠ¡æ¨¡å¼ï¼‰
  ///
  /// æ”¯æŒçš„æ¨¡å‹:
  /// - veo3.1: Google Veo 3.1 (å•å›¾ç‰‡ï¼Œé¦–å¸§)
  /// - veo3.1-components: æ”¯æŒå¤šå›¾ç‰‡è¾“å…¥ï¼ˆæœ€å¤š3å¼ å‚è€ƒå›¾ï¼ŒURLå­—ç¬¦ä¸²æ•°ç»„ï¼‰
  /// - sora-1: OpenAI Sora 1
  /// - sora-2-pro: OpenAI Sora 2 Pro
  ///
  /// å·¥ä½œæµç¨‹ï¼š
  /// 1. æäº¤ä»»åŠ¡åˆ° POST /v1/videosï¼Œè·å– task_id
  /// 2. ä½¿ç”¨ [pollVideoStatus] è½®è¯¢ä»»åŠ¡çŠ¶æ€
  /// 3. å½“ status ä¸º completed æ—¶è·å– video_url
  Future<VideoGenerationResponse> generateVideo({
    required String prompt,
    List<String> imageUrls = const [], // å¤šå¼ å‚è€ƒå›¾URLï¼ˆç›´æ¥ä¼ URLå­—ç¬¦ä¸²ï¼‰
    String seconds = '10',
    String model = 'veo3.1-components',  // é»˜è®¤ä½¿ç”¨ veo3.1-components æ”¯æŒå¤šå›¾
    String size = '1280x720',
    bool sanitizePrompt = false, // æ˜¯å¦æ¸…ç†æç¤ºè¯ï¼ˆé‡è¯•æ—¶ä½¿ç”¨ï¼‰
  }) async {
    // å¦‚æœå¯ç”¨æ¸…ç†ï¼Œå¯¹æç¤ºè¯è¿›è¡Œå®‰å…¨å¤„ç†
    final finalPrompt = sanitizePrompt ? _sanitizeVideoPrompt(prompt) : prompt;

    // ========================================
    // Mock æ¨¡å¼ï¼šç›´æ¥è¿”å›æ¨¡æ‹Ÿç»“æœ
    // ========================================
    if (ApiConfig.USE_MOCK_VIDEO_API) {
      AppLogger.warn('è§†é¢‘ç”Ÿæˆ', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼ï¼Œä¸è°ƒç”¨çœŸå® API');
      AppLogger.info('è§†é¢‘ç”Ÿæˆ', 'å‚è€ƒå›¾æ•°é‡: ${imageUrls.length}');

      await Future.delayed(const Duration(seconds: 2)); // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

      return VideoGenerationResponse(
        id: 'mock_task_${DateTime.now().millisecondsSinceEpoch}',
        object: 'video',
        model: model,
        status: 'completed',
        progress: 100,
        createdAt: DateTime.now().millisecondsSinceEpoch ~/ 1000,
        seconds: seconds,
        videoUrl: ApiConfig.MOCK_VIDEO_URL,
      );
    }

    // ========================================
    // ç”Ÿäº§æ¨¡å¼ï¼šè°ƒç”¨çœŸå® Tuzi Sora API
    // ========================================
    try {
      AppLogger.info('è§†é¢‘ç”Ÿæˆ', 'å¼€å§‹ç”Ÿæˆè§†é¢‘: $finalPrompt, æ—¶é•¿: ${seconds}ç§’, æ¨¡å‹: $model');
      AppLogger.info('è§†é¢‘ç”Ÿæˆ', 'å‚è€ƒå›¾æ•°é‡: ${imageUrls.length}');
      AppLogger.info('è§†é¢‘ç”Ÿæˆ', 'å‚è€ƒå›¾URL: $imageUrls');

      // æ­¥éª¤ 1: å‡†å¤‡ FormData è¯·æ±‚æ•°æ®ï¼ˆAPI è¦æ±‚ multipart/form-data æ ¼å¼ï¼‰
      final formData = FormData.fromMap({
        'model': model,
        'prompt': finalPrompt,
        'seconds': seconds,
        'size': size,
        'watermark': 'false',
      });

      // å¦‚æœæœ‰å‚è€ƒå›¾ï¼Œæ¯å¼ å›¾ç‰‡ä½œä¸ºå•ç‹¬çš„ input_reference å­—æ®µæ·»åŠ 
      // multipart/form-data æ ¼å¼æ”¯æŒåŒåå¤šå€¼
      for (final imageUrl in imageUrls) {
        formData.fields.add(MapEntry('input_reference', imageUrl));
      }

      AppLogger.apiRequestRaw('POST', '/v1/videos', {
        'model': model,
        'prompt': finalPrompt,
        'seconds': seconds,
        'size': size,
        'watermark': 'false',
        'input_reference': imageUrls,
      });

      // æ­¥éª¤ 2: æäº¤ä»»åŠ¡
      final response = await _tuziDio.post(
        '/v1/videos',
        data: formData,
      );

      AppLogger.apiResponseRaw('/v1/videos', response.data);

      final result = VideoGenerationResponse.fromJson(response.data);

      if (result.isCompleted && result.hasVideoUrl) {
        AppLogger.success('è§†é¢‘ç”Ÿæˆ', 'è§†é¢‘ç”ŸæˆæˆåŠŸ: ${result.videoUrl}');
      } else if (result.isFailed) {
        AppLogger.error('è§†é¢‘ç”Ÿæˆ', 'è§†é¢‘ç”Ÿæˆå¤±è´¥: ${result.error}', null, StackTrace.current);
      } else {
        AppLogger.info('è§†é¢‘ç”Ÿæˆ', 'ä»»åŠ¡å·²æäº¤: ${result.id}, çŠ¶æ€: ${result.status}');
      }

      return result;
    } catch (e) {
      AppLogger.error('è§†é¢‘ç”Ÿæˆ', 'ç”Ÿæˆè§†é¢‘å¤±è´¥', e, StackTrace.current);
      throw Exception('è§†é¢‘ç”Ÿæˆé”™è¯¯: $e');
    }
  }

  /// è½®è¯¢è§†é¢‘ç”Ÿæˆä»»åŠ¡çŠ¶æ€ï¼Œç›´åˆ°å®Œæˆæˆ–å¤±è´¥
  ///
  /// å‚æ•°:
  /// - [taskId] ä»»åŠ¡ ID
  /// - [timeout] è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤ 10 åˆ†é’Ÿï¼‰
  /// - [interval] è½®è¯¢é—´éš”ï¼ˆé»˜è®¤ 2 ç§’ï¼‰
  /// - [onProgress] è¿›åº¦å›è°ƒï¼Œæ¯æ¬¡è½®è¯¢æ—¶è°ƒç”¨
  ///
  /// è¿”å›: å®ŒæˆçŠ¶æ€çš„ VideoGenerationResponse
  Future<VideoGenerationResponse> pollVideoStatus({
    required String taskId,
    Duration timeout = const Duration(minutes: 10),
    Duration interval = const Duration(seconds: 2),
    void Function(int progress, String status)? onProgress,
    bool Function()? isCancelled, // å–æ¶ˆæ£€æŸ¥å›è°ƒ
  }) async {
    // ========================================
    // Mock æ¨¡å¼ï¼šç›´æ¥è¿”å›æ¨¡æ‹Ÿå®ŒæˆçŠ¶æ€
    // ========================================
    if (ApiConfig.USE_MOCK_VIDEO_API) {
      AppLogger.warn('è§†é¢‘è½®è¯¢', 'ğŸ§ª Mock æ¨¡å¼ï¼Œæ¨¡æ‹Ÿè½®è¯¢è¿‡ç¨‹');

      // æ¨¡æ‹Ÿè¿›åº¦å˜åŒ–
      for (int progress = 0; progress <= 100; progress += 25) {
        // æ£€æŸ¥å–æ¶ˆ
        if (isCancelled?.call() == true) {
          throw Exception('æ“ä½œå·²å–æ¶ˆ');
        }
        await Future.delayed(const Duration(milliseconds: 500)); // Mockæ¨¡å¼ç”¨æ›´çŸ­å»¶è¿Ÿ
        AppLogger.info('è§†é¢‘è½®è¯¢', 'æ¨¡æ‹Ÿè¿›åº¦: $progress%');
        onProgress?.call(progress, 'in_progress');
      }

      return VideoGenerationResponse(
        id: taskId,
        object: 'video',
        model: 'veo3.1',
        status: 'completed',
        progress: 100,
        createdAt: DateTime.now().millisecondsSinceEpoch ~/ 1000,
        seconds: '10',
        videoUrl: ApiConfig.MOCK_VIDEO_URL,
      );
    }

    // ========================================
    // ç”Ÿäº§æ¨¡å¼ï¼šçœŸå®è½®è¯¢
    // ========================================
    final startTime = DateTime.now();
    AppLogger.info('è§†é¢‘è½®è¯¢', 'å¼€å§‹è½®è¯¢ä»»åŠ¡: $taskId');

    try {
      while (true) {
        // æ£€æŸ¥å–æ¶ˆï¼ˆåœ¨æ¯æ¬¡å¾ªç¯å¼€å§‹æ—¶æ£€æŸ¥ï¼‰
        if (isCancelled?.call() == true) {
          AppLogger.warn('è§†é¢‘è½®è¯¢', 'ç”¨æˆ·å–æ¶ˆæ“ä½œ');
          throw Exception('æ“ä½œå·²å–æ¶ˆ');
        }

        // æ£€æŸ¥è¶…æ—¶
        if (DateTime.now().difference(startTime) > timeout) {
          throw Exception('è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼ˆè¶…è¿‡ ${timeout.inMinutes} åˆ†é’Ÿï¼‰');
        }

        // æŸ¥è¯¢çŠ¶æ€
        final response = await _tuziDio.get('/v1/videos/$taskId');
        final result = VideoGenerationResponse.fromJson(response.data);

        AppLogger.apiResponseRaw('/v1/videos/$taskId', response.data);
        AppLogger.info('è§†é¢‘è½®è¯¢', 'çŠ¶æ€: ${result.status}, è¿›åº¦: ${result.progress ?? 0}%');

        // å›è°ƒè¿›åº¦æ›´æ–°
        onProgress?.call(result.progress ?? 0, result.status ?? 'unknown');

        // æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if (result.isCompleted) {
          if (result.hasVideoUrl) {
            AppLogger.success('è§†é¢‘è½®è¯¢', 'è§†é¢‘ç”Ÿæˆå®Œæˆ: ${result.videoUrl}');
            return result;
          } else {
            throw Exception('ä»»åŠ¡å·²å®Œæˆä½†æ²¡æœ‰è§†é¢‘ URL');
          }
        }

        // æ£€æŸ¥æ˜¯å¦å¤±è´¥
        if (result.isFailed) {
          throw Exception('è§†é¢‘ç”Ÿæˆå¤±è´¥: ${result.error ?? "æœªçŸ¥é”™è¯¯"}');
        }

        // ç­‰å¾…åç»§ç»­è½®è¯¢ - åˆ†ç‰‡ç­‰å¾…ä»¥æ›´å¿«å“åº”å–æ¶ˆ
        final waitSteps = 5; // å°†ç­‰å¾…åˆ†æˆ5æ®µï¼Œæ¯æ®µ0.4ç§’ï¼ˆæ€»å…±2ç§’ï¼‰
        for (int i = 0; i < waitSteps; i++) {
          await Future.delayed(interval ~/ waitSteps);
          // æ¯å°æ®µéƒ½æ£€æŸ¥å–æ¶ˆï¼Œæé«˜å“åº”é€Ÿåº¦
          if (isCancelled?.call() == true) {
            AppLogger.warn('è§†é¢‘è½®è¯¢', 'ç­‰å¾…æœŸé—´ç”¨æˆ·å–æ¶ˆæ“ä½œ');
            throw Exception('æ“ä½œå·²å–æ¶ˆ');
          }
        }
      }
    } catch (e) {
      AppLogger.error('è§†é¢‘è½®è¯¢', 'è½®è¯¢å¤±è´¥', e, StackTrace.current);
      rethrow;
    }
  }

  // ==================== å·¥å…·æ–¹æ³• ====================

  /// ä¸‹è½½ä»»ä½•æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
  Future<File> downloadFile(String url, {String? filename}) async {
    try {
      final response = await _dio.get(
        url,
        options: Options(responseType: ResponseType.bytes),
      );

      final tempDir = await getTemporaryDirectory();
      final finalFilename = filename ??
          'file_${DateTime.now().millisecondsSinceEpoch}${path.extension(url)}';
      final filePath = path.join(tempDir.path, finalFilename);

      final file = File(filePath);
      await file.writeAsBytes(response.data as List<int>);

      return file;
    } catch (e) {
      throw Exception('æ–‡ä»¶ä¸‹è½½é”™è¯¯: $e');
    }
  }
}
